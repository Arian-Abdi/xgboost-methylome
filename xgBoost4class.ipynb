{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import sklearn as sk\n",
    "import cupy as cp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y:\\UGent\\BioLizard - General\\data\\methylome\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "directory = r\"Y:\\UGent\\BioLizard - General\\data\\methylome\"\n",
    "os.chdir(directory)\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "metaData=pd.read_csv(\"Y:/meta_data.csv\")\n",
    "metaData=pd.DataFrame(metaData).reset_index(drop=True)\n",
    "metaData = metaData.drop(metaData.columns[0], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idBiospe</th>\n",
       "      <th>idwoman</th>\n",
       "      <th>cpn234_tad2</th>\n",
       "      <th>cpn234_tas2</th>\n",
       "      <th>cpn234_tad3</th>\n",
       "      <th>cpn234_tas3</th>\n",
       "      <th>cpn234_tad4</th>\n",
       "      <th>cpn234_tas4</th>\n",
       "      <th>cpn234_tad5</th>\n",
       "      <th>cpn234_tas5</th>\n",
       "      <th>...</th>\n",
       "      <th>c_igu_muacaz6</th>\n",
       "      <th>c_igu_bmi9</th>\n",
       "      <th>c_igu_hcaz9</th>\n",
       "      <th>c_igu_muacaz9</th>\n",
       "      <th>c_igu_bmi12</th>\n",
       "      <th>c_igu_hcaz12</th>\n",
       "      <th>c_igu_muacaz12</th>\n",
       "      <th>biospe_neonatal_mortality</th>\n",
       "      <th>last_visit_death</th>\n",
       "      <th>_list_tad</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>101</td>\n",
       "      <td>40262</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.08</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>.</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>102</td>\n",
       "      <td>16016_2</td>\n",
       "      <td>8.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>.</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>103</td>\n",
       "      <td>40274</td>\n",
       "      <td>6.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.61</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>.</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>104</td>\n",
       "      <td>16025_3</td>\n",
       "      <td>6.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>.</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>105</td>\n",
       "      <td>40254</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.95</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>.</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 450 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   idBiospe  idwoman  cpn234_tad2  cpn234_tas2  cpn234_tad3  cpn234_tas3  \\\n",
       "0       101    40262          6.0          9.0          5.0         12.0   \n",
       "1       102  16016_2          8.0         12.0          8.0         12.0   \n",
       "2       103    40274          6.0         10.0          7.0         10.0   \n",
       "3       104  16025_3          6.0         10.0          7.0         11.0   \n",
       "4       105    40254          5.0         10.0          6.0         10.0   \n",
       "\n",
       "   cpn234_tad4  cpn234_tas4  cpn234_tad5  cpn234_tas5  ...  c_igu_muacaz6  \\\n",
       "0          7.0         12.0          NaN          NaN  ...           0.08   \n",
       "1          8.0         14.0          NaN          NaN  ...          -1.20   \n",
       "2          6.0         11.0          NaN          NaN  ...          -0.61   \n",
       "3          6.0         11.0          NaN          NaN  ...           0.09   \n",
       "4          6.0         11.0          NaN          NaN  ...          -0.95   \n",
       "\n",
       "   c_igu_bmi9  c_igu_hcaz9  c_igu_muacaz9 c_igu_bmi12  c_igu_hcaz12  \\\n",
       "0         NaN          NaN            NaN         NaN           NaN   \n",
       "1         NaN          NaN            NaN         NaN           NaN   \n",
       "2         NaN          NaN            NaN         NaN           NaN   \n",
       "3         NaN          NaN            NaN         NaN           NaN   \n",
       "4         NaN          NaN            NaN         NaN           NaN   \n",
       "\n",
       "  c_igu_muacaz12  biospe_neonatal_mortality last_visit_death  _list_tad  \n",
       "0            NaN                          0                .          3  \n",
       "1            NaN                          0                .          3  \n",
       "2            NaN                          0                .          3  \n",
       "3            NaN                          0                .          3  \n",
       "4            NaN                          0                .          3  \n",
       "\n",
       "[5 rows x 450 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metaData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampleSheet = pd.read_csv(\"../../data/methylome/sampleSheet.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sample_ID</th>\n",
       "      <th>Plate_ID</th>\n",
       "      <th>Sample_Well</th>\n",
       "      <th>Sentrix_ID</th>\n",
       "      <th>Sentrix_Position</th>\n",
       "      <th>Date</th>\n",
       "      <th>Basename</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>102</td>\n",
       "      <td>BC78</td>\n",
       "      <td>D1</td>\n",
       "      <td>2.060000e+11</td>\n",
       "      <td>R04C01</td>\n",
       "      <td>13/09/2022</td>\n",
       "      <td>206402350107_R04C01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>103</td>\n",
       "      <td>BC79</td>\n",
       "      <td>C4</td>\n",
       "      <td>2.070000e+11</td>\n",
       "      <td>R03C01</td>\n",
       "      <td>28/09/2022</td>\n",
       "      <td>206644410180_R03C01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>104</td>\n",
       "      <td>BC78</td>\n",
       "      <td>C2</td>\n",
       "      <td>2.060000e+11</td>\n",
       "      <td>R03C01</td>\n",
       "      <td>13/09/2022</td>\n",
       "      <td>206402350116_R03C01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>106</td>\n",
       "      <td>BC78</td>\n",
       "      <td>G12</td>\n",
       "      <td>2.060000e+11</td>\n",
       "      <td>R07C01</td>\n",
       "      <td>13/09/2022</td>\n",
       "      <td>206425830038_R07C01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>107</td>\n",
       "      <td>BC79</td>\n",
       "      <td>B3</td>\n",
       "      <td>2.070000e+11</td>\n",
       "      <td>R02C01</td>\n",
       "      <td>28/09/2022</td>\n",
       "      <td>206644410103_R02C01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sample_ID Plate_ID Sample_Well    Sentrix_ID Sentrix_Position        Date  \\\n",
       "0        102     BC78          D1  2.060000e+11           R04C01  13/09/2022   \n",
       "1        103     BC79          C4  2.070000e+11           R03C01  28/09/2022   \n",
       "2        104     BC78          C2  2.060000e+11           R03C01  13/09/2022   \n",
       "3        106     BC78         G12  2.060000e+11           R07C01  13/09/2022   \n",
       "4        107     BC79          B3  2.070000e+11           R02C01  28/09/2022   \n",
       "\n",
       "              Basename  \n",
       "0  206402350107_R04C01  \n",
       "1  206644410180_R03C01  \n",
       "2  206402350116_R03C01  \n",
       "3  206425830038_R07C01  \n",
       "4  206644410103_R02C01  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampleSheet.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "sampleSheet = pd.read_csv(\"../../data/methylome/sampleSheet.csv\")\n",
    "methylome = pd.read_csv(\"../../data/methylome/20240411MethylomeDataBetasWithProbId.csv\")\n",
    "\n",
    "# Process methylome data\n",
    "methylome = methylome.set_index(\"ProbeID\").T\n",
    "methylome = methylome.reset_index().rename(columns={\"index\": \"Basename\"})\n",
    "methylome = methylome.merge(sampleSheet[[\"Basename\", \"Sample_ID\"]], on=\"Basename\", how=\"left\")\n",
    "methylome = methylome.drop(columns=[\"Basename\"]).rename(columns={\"Sample_ID\": \"idBiospe\"})\n",
    "methylome = methylome[[\"idBiospe\"] + [col for col in methylome.columns if col != \"idBiospe\"]]\n",
    "\n",
    "# Assuming metaData is another dataframe that needs to be loaded\n",
    "meta_data = metaData  # Replace with actual path to metaData file\n",
    "methylome = methylome.merge(meta_data[[\"idBiospe\", \"code_bep_n\"]], on=\"idBiospe\", how=\"left\")\n",
    "methylome = methylome.rename(columns={\"code_bep_n\": \"class\"})\n",
    "methylome[\"class\"] = methylome[\"class\"] - 1\n",
    "methylome[\"timePoint\"] = \"Pn56\"\n",
    "methylome = methylome.sort_values(by=[\"timePoint\", \"idBiospe\"])\n",
    "methylome = methylome[[\"timePoint\", \"idBiospe\", \"class\"] + [col for col in methylome.columns if col not in [\"timePoint\", \"idBiospe\", \"class\"]]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timePoint</th>\n",
       "      <th>idBiospe</th>\n",
       "      <th>class</th>\n",
       "      <th>cg14817997</th>\n",
       "      <th>cg26928153</th>\n",
       "      <th>cg16269199</th>\n",
       "      <th>cg13869341</th>\n",
       "      <th>cg14008030</th>\n",
       "      <th>cg12045430</th>\n",
       "      <th>cg20826792</th>\n",
       "      <th>...</th>\n",
       "      <th>cg17939569</th>\n",
       "      <th>cg13365400</th>\n",
       "      <th>cg02600718</th>\n",
       "      <th>cg21106100</th>\n",
       "      <th>cg08265308</th>\n",
       "      <th>cg10488260</th>\n",
       "      <th>cg14273923</th>\n",
       "      <th>cg09748881</th>\n",
       "      <th>cg07587934</th>\n",
       "      <th>cg16855331</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Pn56</td>\n",
       "      <td>102</td>\n",
       "      <td>2</td>\n",
       "      <td>0.370702</td>\n",
       "      <td>0.906810</td>\n",
       "      <td>0.729572</td>\n",
       "      <td>0.919086</td>\n",
       "      <td>0.748790</td>\n",
       "      <td>0.131226</td>\n",
       "      <td>0.131664</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.204499</td>\n",
       "      <td>0.233191</td>\n",
       "      <td>0.410137</td>\n",
       "      <td>0.116070</td>\n",
       "      <td>0.238445</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.806420</td>\n",
       "      <td>0.415945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Pn56</td>\n",
       "      <td>103</td>\n",
       "      <td>2</td>\n",
       "      <td>0.352146</td>\n",
       "      <td>0.475196</td>\n",
       "      <td>0.227495</td>\n",
       "      <td>0.772063</td>\n",
       "      <td>0.737550</td>\n",
       "      <td>0.225267</td>\n",
       "      <td>0.213943</td>\n",
       "      <td>...</td>\n",
       "      <td>0.741882</td>\n",
       "      <td>0.607857</td>\n",
       "      <td>0.247206</td>\n",
       "      <td>0.637003</td>\n",
       "      <td>0.849188</td>\n",
       "      <td>0.504236</td>\n",
       "      <td>0.440615</td>\n",
       "      <td>0.823711</td>\n",
       "      <td>0.777729</td>\n",
       "      <td>0.567635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Pn56</td>\n",
       "      <td>104</td>\n",
       "      <td>1</td>\n",
       "      <td>0.307659</td>\n",
       "      <td>0.872990</td>\n",
       "      <td>0.657483</td>\n",
       "      <td>0.819911</td>\n",
       "      <td>0.548639</td>\n",
       "      <td>0.126281</td>\n",
       "      <td>0.118666</td>\n",
       "      <td>...</td>\n",
       "      <td>0.227705</td>\n",
       "      <td>0.235356</td>\n",
       "      <td>0.231018</td>\n",
       "      <td>0.234811</td>\n",
       "      <td>0.420113</td>\n",
       "      <td>0.139597</td>\n",
       "      <td>0.223410</td>\n",
       "      <td>0.199689</td>\n",
       "      <td>0.807111</td>\n",
       "      <td>0.493500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pn56</td>\n",
       "      <td>106</td>\n",
       "      <td>0</td>\n",
       "      <td>0.369779</td>\n",
       "      <td>0.875169</td>\n",
       "      <td>0.725316</td>\n",
       "      <td>0.909891</td>\n",
       "      <td>0.587720</td>\n",
       "      <td>0.091899</td>\n",
       "      <td>0.120725</td>\n",
       "      <td>...</td>\n",
       "      <td>0.815071</td>\n",
       "      <td>0.513299</td>\n",
       "      <td>0.249403</td>\n",
       "      <td>0.745385</td>\n",
       "      <td>0.924718</td>\n",
       "      <td>0.591618</td>\n",
       "      <td>0.713801</td>\n",
       "      <td>0.852716</td>\n",
       "      <td>0.782532</td>\n",
       "      <td>0.491458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pn56</td>\n",
       "      <td>107</td>\n",
       "      <td>0</td>\n",
       "      <td>0.325455</td>\n",
       "      <td>0.826068</td>\n",
       "      <td>0.612782</td>\n",
       "      <td>0.738983</td>\n",
       "      <td>0.641742</td>\n",
       "      <td>0.245444</td>\n",
       "      <td>0.265556</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.261898</td>\n",
       "      <td>0.229423</td>\n",
       "      <td>0.438345</td>\n",
       "      <td>0.211108</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.815358</td>\n",
       "      <td>0.434790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Pn56</td>\n",
       "      <td>109</td>\n",
       "      <td>1</td>\n",
       "      <td>0.335254</td>\n",
       "      <td>0.859299</td>\n",
       "      <td>0.720324</td>\n",
       "      <td>0.859915</td>\n",
       "      <td>0.626692</td>\n",
       "      <td>0.114128</td>\n",
       "      <td>0.112664</td>\n",
       "      <td>...</td>\n",
       "      <td>0.750602</td>\n",
       "      <td>0.473561</td>\n",
       "      <td>0.227851</td>\n",
       "      <td>0.899750</td>\n",
       "      <td>0.924760</td>\n",
       "      <td>0.391456</td>\n",
       "      <td>0.810127</td>\n",
       "      <td>0.746885</td>\n",
       "      <td>0.818290</td>\n",
       "      <td>0.505662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Pn56</td>\n",
       "      <td>110</td>\n",
       "      <td>2</td>\n",
       "      <td>0.554714</td>\n",
       "      <td>0.881504</td>\n",
       "      <td>0.687885</td>\n",
       "      <td>0.851117</td>\n",
       "      <td>0.669206</td>\n",
       "      <td>0.105999</td>\n",
       "      <td>0.162168</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.246564</td>\n",
       "      <td>0.253218</td>\n",
       "      <td>0.412819</td>\n",
       "      <td>0.138194</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.216414</td>\n",
       "      <td>0.823519</td>\n",
       "      <td>0.465784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Pn56</td>\n",
       "      <td>112</td>\n",
       "      <td>0</td>\n",
       "      <td>0.665123</td>\n",
       "      <td>0.936929</td>\n",
       "      <td>0.773192</td>\n",
       "      <td>0.832327</td>\n",
       "      <td>0.609909</td>\n",
       "      <td>0.126268</td>\n",
       "      <td>0.186922</td>\n",
       "      <td>...</td>\n",
       "      <td>0.230692</td>\n",
       "      <td>0.227732</td>\n",
       "      <td>0.254356</td>\n",
       "      <td>0.225905</td>\n",
       "      <td>0.389093</td>\n",
       "      <td>0.189091</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.798229</td>\n",
       "      <td>0.417867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Pn56</td>\n",
       "      <td>113</td>\n",
       "      <td>0</td>\n",
       "      <td>0.369006</td>\n",
       "      <td>0.864040</td>\n",
       "      <td>0.693321</td>\n",
       "      <td>0.847711</td>\n",
       "      <td>0.721725</td>\n",
       "      <td>0.137078</td>\n",
       "      <td>0.113993</td>\n",
       "      <td>...</td>\n",
       "      <td>0.222673</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.219803</td>\n",
       "      <td>0.463869</td>\n",
       "      <td>0.168533</td>\n",
       "      <td>0.245503</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.851469</td>\n",
       "      <td>0.416282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Pn56</td>\n",
       "      <td>114</td>\n",
       "      <td>2</td>\n",
       "      <td>0.309475</td>\n",
       "      <td>0.605469</td>\n",
       "      <td>0.559015</td>\n",
       "      <td>0.853587</td>\n",
       "      <td>0.735287</td>\n",
       "      <td>0.077172</td>\n",
       "      <td>0.130759</td>\n",
       "      <td>...</td>\n",
       "      <td>0.768983</td>\n",
       "      <td>0.529242</td>\n",
       "      <td>0.219134</td>\n",
       "      <td>0.804604</td>\n",
       "      <td>0.930088</td>\n",
       "      <td>0.538191</td>\n",
       "      <td>0.855217</td>\n",
       "      <td>0.764714</td>\n",
       "      <td>0.817391</td>\n",
       "      <td>0.626756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Pn56</td>\n",
       "      <td>118</td>\n",
       "      <td>1</td>\n",
       "      <td>0.670897</td>\n",
       "      <td>0.939727</td>\n",
       "      <td>0.774316</td>\n",
       "      <td>0.844640</td>\n",
       "      <td>0.677905</td>\n",
       "      <td>0.101623</td>\n",
       "      <td>0.158239</td>\n",
       "      <td>...</td>\n",
       "      <td>0.600804</td>\n",
       "      <td>0.413791</td>\n",
       "      <td>0.232792</td>\n",
       "      <td>0.878060</td>\n",
       "      <td>0.934445</td>\n",
       "      <td>0.405269</td>\n",
       "      <td>0.762313</td>\n",
       "      <td>0.778833</td>\n",
       "      <td>0.755422</td>\n",
       "      <td>0.394690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Pn56</td>\n",
       "      <td>119</td>\n",
       "      <td>2</td>\n",
       "      <td>0.523718</td>\n",
       "      <td>0.893079</td>\n",
       "      <td>0.721592</td>\n",
       "      <td>0.864005</td>\n",
       "      <td>0.670722</td>\n",
       "      <td>0.122745</td>\n",
       "      <td>0.167697</td>\n",
       "      <td>...</td>\n",
       "      <td>0.254087</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.216899</td>\n",
       "      <td>0.228183</td>\n",
       "      <td>0.420426</td>\n",
       "      <td>0.137345</td>\n",
       "      <td>0.224384</td>\n",
       "      <td>0.228634</td>\n",
       "      <td>0.765352</td>\n",
       "      <td>0.416575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Pn56</td>\n",
       "      <td>120</td>\n",
       "      <td>2</td>\n",
       "      <td>0.663641</td>\n",
       "      <td>0.933071</td>\n",
       "      <td>0.804827</td>\n",
       "      <td>0.928259</td>\n",
       "      <td>0.627448</td>\n",
       "      <td>0.122829</td>\n",
       "      <td>0.164834</td>\n",
       "      <td>...</td>\n",
       "      <td>0.771967</td>\n",
       "      <td>0.513431</td>\n",
       "      <td>0.232924</td>\n",
       "      <td>0.862327</td>\n",
       "      <td>0.920467</td>\n",
       "      <td>0.367181</td>\n",
       "      <td>0.664971</td>\n",
       "      <td>0.814897</td>\n",
       "      <td>0.795508</td>\n",
       "      <td>0.462717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Pn56</td>\n",
       "      <td>121</td>\n",
       "      <td>0</td>\n",
       "      <td>0.415127</td>\n",
       "      <td>0.846561</td>\n",
       "      <td>0.640467</td>\n",
       "      <td>0.895844</td>\n",
       "      <td>0.677762</td>\n",
       "      <td>0.127385</td>\n",
       "      <td>0.135253</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.205848</td>\n",
       "      <td>0.453384</td>\n",
       "      <td>0.137929</td>\n",
       "      <td>0.229974</td>\n",
       "      <td>0.233784</td>\n",
       "      <td>0.828704</td>\n",
       "      <td>0.429640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Pn56</td>\n",
       "      <td>122</td>\n",
       "      <td>1</td>\n",
       "      <td>0.526088</td>\n",
       "      <td>0.894585</td>\n",
       "      <td>0.703535</td>\n",
       "      <td>0.808907</td>\n",
       "      <td>0.661538</td>\n",
       "      <td>0.123618</td>\n",
       "      <td>0.147830</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.256320</td>\n",
       "      <td>0.314065</td>\n",
       "      <td>0.223014</td>\n",
       "      <td>0.385513</td>\n",
       "      <td>0.100546</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.746832</td>\n",
       "      <td>0.412882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Pn56</td>\n",
       "      <td>123</td>\n",
       "      <td>0</td>\n",
       "      <td>0.669600</td>\n",
       "      <td>0.906209</td>\n",
       "      <td>0.740899</td>\n",
       "      <td>0.920883</td>\n",
       "      <td>0.682771</td>\n",
       "      <td>0.100978</td>\n",
       "      <td>0.145999</td>\n",
       "      <td>...</td>\n",
       "      <td>0.671044</td>\n",
       "      <td>0.478505</td>\n",
       "      <td>0.260438</td>\n",
       "      <td>0.850432</td>\n",
       "      <td>0.902303</td>\n",
       "      <td>0.276911</td>\n",
       "      <td>0.606481</td>\n",
       "      <td>0.749622</td>\n",
       "      <td>0.713177</td>\n",
       "      <td>0.393546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Pn56</td>\n",
       "      <td>124</td>\n",
       "      <td>3</td>\n",
       "      <td>0.569146</td>\n",
       "      <td>0.929941</td>\n",
       "      <td>0.725161</td>\n",
       "      <td>0.826462</td>\n",
       "      <td>0.638250</td>\n",
       "      <td>0.119335</td>\n",
       "      <td>0.158341</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.282263</td>\n",
       "      <td>0.214288</td>\n",
       "      <td>0.432736</td>\n",
       "      <td>0.136878</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.806033</td>\n",
       "      <td>0.390286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Pn56</td>\n",
       "      <td>125</td>\n",
       "      <td>0</td>\n",
       "      <td>0.691883</td>\n",
       "      <td>0.934744</td>\n",
       "      <td>0.799537</td>\n",
       "      <td>0.813666</td>\n",
       "      <td>0.600773</td>\n",
       "      <td>0.096311</td>\n",
       "      <td>0.137092</td>\n",
       "      <td>...</td>\n",
       "      <td>0.762447</td>\n",
       "      <td>0.477126</td>\n",
       "      <td>0.350102</td>\n",
       "      <td>0.845531</td>\n",
       "      <td>0.921718</td>\n",
       "      <td>0.316076</td>\n",
       "      <td>0.739091</td>\n",
       "      <td>0.754490</td>\n",
       "      <td>0.812482</td>\n",
       "      <td>0.448128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Pn56</td>\n",
       "      <td>126</td>\n",
       "      <td>3</td>\n",
       "      <td>0.443104</td>\n",
       "      <td>0.862850</td>\n",
       "      <td>0.689389</td>\n",
       "      <td>0.772764</td>\n",
       "      <td>0.600399</td>\n",
       "      <td>0.101740</td>\n",
       "      <td>0.103942</td>\n",
       "      <td>...</td>\n",
       "      <td>0.801542</td>\n",
       "      <td>0.563342</td>\n",
       "      <td>0.255242</td>\n",
       "      <td>0.858453</td>\n",
       "      <td>0.927807</td>\n",
       "      <td>0.570651</td>\n",
       "      <td>0.711534</td>\n",
       "      <td>0.842075</td>\n",
       "      <td>0.705437</td>\n",
       "      <td>0.521170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Pn56</td>\n",
       "      <td>127</td>\n",
       "      <td>1</td>\n",
       "      <td>0.263530</td>\n",
       "      <td>0.432865</td>\n",
       "      <td>0.432865</td>\n",
       "      <td>0.865834</td>\n",
       "      <td>0.606477</td>\n",
       "      <td>0.110302</td>\n",
       "      <td>0.092445</td>\n",
       "      <td>...</td>\n",
       "      <td>0.765222</td>\n",
       "      <td>0.640587</td>\n",
       "      <td>0.203927</td>\n",
       "      <td>0.770290</td>\n",
       "      <td>0.958099</td>\n",
       "      <td>0.477990</td>\n",
       "      <td>0.518595</td>\n",
       "      <td>0.829578</td>\n",
       "      <td>0.829165</td>\n",
       "      <td>0.578922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Pn56</td>\n",
       "      <td>128</td>\n",
       "      <td>2</td>\n",
       "      <td>0.343815</td>\n",
       "      <td>0.456422</td>\n",
       "      <td>0.432495</td>\n",
       "      <td>0.897301</td>\n",
       "      <td>0.540110</td>\n",
       "      <td>0.107610</td>\n",
       "      <td>0.132012</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.232594</td>\n",
       "      <td>0.217625</td>\n",
       "      <td>0.461653</td>\n",
       "      <td>0.204903</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.798377</td>\n",
       "      <td>0.418920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Pn56</td>\n",
       "      <td>129</td>\n",
       "      <td>1</td>\n",
       "      <td>0.696170</td>\n",
       "      <td>0.963348</td>\n",
       "      <td>0.850369</td>\n",
       "      <td>0.813896</td>\n",
       "      <td>0.614475</td>\n",
       "      <td>0.066072</td>\n",
       "      <td>0.131415</td>\n",
       "      <td>...</td>\n",
       "      <td>0.742420</td>\n",
       "      <td>0.469953</td>\n",
       "      <td>0.249524</td>\n",
       "      <td>0.905930</td>\n",
       "      <td>0.934995</td>\n",
       "      <td>0.515482</td>\n",
       "      <td>0.841846</td>\n",
       "      <td>0.780279</td>\n",
       "      <td>0.768973</td>\n",
       "      <td>0.451674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Pn56</td>\n",
       "      <td>130</td>\n",
       "      <td>3</td>\n",
       "      <td>0.335158</td>\n",
       "      <td>0.801576</td>\n",
       "      <td>0.581277</td>\n",
       "      <td>0.837545</td>\n",
       "      <td>0.613343</td>\n",
       "      <td>0.089275</td>\n",
       "      <td>0.105144</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.234089</td>\n",
       "      <td>0.229211</td>\n",
       "      <td>0.451202</td>\n",
       "      <td>0.127532</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.208099</td>\n",
       "      <td>0.853916</td>\n",
       "      <td>0.466294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Pn56</td>\n",
       "      <td>132</td>\n",
       "      <td>1</td>\n",
       "      <td>0.352136</td>\n",
       "      <td>0.776721</td>\n",
       "      <td>0.579312</td>\n",
       "      <td>0.795243</td>\n",
       "      <td>0.666121</td>\n",
       "      <td>0.099218</td>\n",
       "      <td>0.097875</td>\n",
       "      <td>...</td>\n",
       "      <td>0.789760</td>\n",
       "      <td>0.543899</td>\n",
       "      <td>0.265834</td>\n",
       "      <td>0.906830</td>\n",
       "      <td>0.912564</td>\n",
       "      <td>0.374315</td>\n",
       "      <td>0.725956</td>\n",
       "      <td>0.839753</td>\n",
       "      <td>0.775440</td>\n",
       "      <td>0.495858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Pn56</td>\n",
       "      <td>133</td>\n",
       "      <td>1</td>\n",
       "      <td>0.279985</td>\n",
       "      <td>0.785165</td>\n",
       "      <td>0.532702</td>\n",
       "      <td>0.870805</td>\n",
       "      <td>0.643749</td>\n",
       "      <td>0.098625</td>\n",
       "      <td>0.105695</td>\n",
       "      <td>...</td>\n",
       "      <td>0.788581</td>\n",
       "      <td>0.527433</td>\n",
       "      <td>0.297396</td>\n",
       "      <td>0.868786</td>\n",
       "      <td>0.877040</td>\n",
       "      <td>0.603917</td>\n",
       "      <td>0.799931</td>\n",
       "      <td>0.838740</td>\n",
       "      <td>0.803204</td>\n",
       "      <td>0.451297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Pn56</td>\n",
       "      <td>134</td>\n",
       "      <td>3</td>\n",
       "      <td>0.671811</td>\n",
       "      <td>0.540049</td>\n",
       "      <td>0.499910</td>\n",
       "      <td>0.694197</td>\n",
       "      <td>0.598383</td>\n",
       "      <td>0.239695</td>\n",
       "      <td>0.258341</td>\n",
       "      <td>...</td>\n",
       "      <td>0.812545</td>\n",
       "      <td>0.555426</td>\n",
       "      <td>0.273489</td>\n",
       "      <td>0.772869</td>\n",
       "      <td>0.898933</td>\n",
       "      <td>0.388806</td>\n",
       "      <td>0.653115</td>\n",
       "      <td>0.768496</td>\n",
       "      <td>0.716652</td>\n",
       "      <td>0.449627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Pn56</td>\n",
       "      <td>135</td>\n",
       "      <td>2</td>\n",
       "      <td>0.243923</td>\n",
       "      <td>0.517706</td>\n",
       "      <td>0.437407</td>\n",
       "      <td>0.923877</td>\n",
       "      <td>0.762719</td>\n",
       "      <td>0.148420</td>\n",
       "      <td>0.119298</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.231941</td>\n",
       "      <td>0.433197</td>\n",
       "      <td>0.141837</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.829540</td>\n",
       "      <td>0.565420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Pn56</td>\n",
       "      <td>136</td>\n",
       "      <td>0</td>\n",
       "      <td>0.329678</td>\n",
       "      <td>0.433610</td>\n",
       "      <td>0.433610</td>\n",
       "      <td>0.870410</td>\n",
       "      <td>0.598144</td>\n",
       "      <td>0.098938</td>\n",
       "      <td>0.110624</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.236782</td>\n",
       "      <td>0.219070</td>\n",
       "      <td>0.251683</td>\n",
       "      <td>0.461159</td>\n",
       "      <td>0.135706</td>\n",
       "      <td>0.231465</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.825574</td>\n",
       "      <td>0.429536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Pn56</td>\n",
       "      <td>137</td>\n",
       "      <td>2</td>\n",
       "      <td>0.283348</td>\n",
       "      <td>0.900158</td>\n",
       "      <td>0.728263</td>\n",
       "      <td>0.824126</td>\n",
       "      <td>0.555251</td>\n",
       "      <td>0.112228</td>\n",
       "      <td>0.146407</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.238849</td>\n",
       "      <td>0.246116</td>\n",
       "      <td>0.430747</td>\n",
       "      <td>0.156751</td>\n",
       "      <td>0.234477</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.798229</td>\n",
       "      <td>0.457896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Pn56</td>\n",
       "      <td>138</td>\n",
       "      <td>0</td>\n",
       "      <td>0.631969</td>\n",
       "      <td>0.633088</td>\n",
       "      <td>0.479257</td>\n",
       "      <td>0.782405</td>\n",
       "      <td>0.646664</td>\n",
       "      <td>0.230900</td>\n",
       "      <td>0.230941</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.237234</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.145440</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.605348</td>\n",
       "      <td>0.688054</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30 rows × 865862 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   timePoint  idBiospe  class  cg14817997  cg26928153  cg16269199  cg13869341  \\\n",
       "0       Pn56       102      2    0.370702    0.906810    0.729572    0.919086   \n",
       "1       Pn56       103      2    0.352146    0.475196    0.227495    0.772063   \n",
       "2       Pn56       104      1    0.307659    0.872990    0.657483    0.819911   \n",
       "3       Pn56       106      0    0.369779    0.875169    0.725316    0.909891   \n",
       "4       Pn56       107      0    0.325455    0.826068    0.612782    0.738983   \n",
       "5       Pn56       109      1    0.335254    0.859299    0.720324    0.859915   \n",
       "6       Pn56       110      2    0.554714    0.881504    0.687885    0.851117   \n",
       "7       Pn56       112      0    0.665123    0.936929    0.773192    0.832327   \n",
       "8       Pn56       113      0    0.369006    0.864040    0.693321    0.847711   \n",
       "9       Pn56       114      2    0.309475    0.605469    0.559015    0.853587   \n",
       "10      Pn56       118      1    0.670897    0.939727    0.774316    0.844640   \n",
       "11      Pn56       119      2    0.523718    0.893079    0.721592    0.864005   \n",
       "12      Pn56       120      2    0.663641    0.933071    0.804827    0.928259   \n",
       "13      Pn56       121      0    0.415127    0.846561    0.640467    0.895844   \n",
       "14      Pn56       122      1    0.526088    0.894585    0.703535    0.808907   \n",
       "15      Pn56       123      0    0.669600    0.906209    0.740899    0.920883   \n",
       "16      Pn56       124      3    0.569146    0.929941    0.725161    0.826462   \n",
       "17      Pn56       125      0    0.691883    0.934744    0.799537    0.813666   \n",
       "18      Pn56       126      3    0.443104    0.862850    0.689389    0.772764   \n",
       "19      Pn56       127      1    0.263530    0.432865    0.432865    0.865834   \n",
       "20      Pn56       128      2    0.343815    0.456422    0.432495    0.897301   \n",
       "21      Pn56       129      1    0.696170    0.963348    0.850369    0.813896   \n",
       "22      Pn56       130      3    0.335158    0.801576    0.581277    0.837545   \n",
       "23      Pn56       132      1    0.352136    0.776721    0.579312    0.795243   \n",
       "24      Pn56       133      1    0.279985    0.785165    0.532702    0.870805   \n",
       "25      Pn56       134      3    0.671811    0.540049    0.499910    0.694197   \n",
       "26      Pn56       135      2    0.243923    0.517706    0.437407    0.923877   \n",
       "27      Pn56       136      0    0.329678    0.433610    0.433610    0.870410   \n",
       "28      Pn56       137      2    0.283348    0.900158    0.728263    0.824126   \n",
       "29      Pn56       138      0    0.631969    0.633088    0.479257    0.782405   \n",
       "\n",
       "    cg14008030  cg12045430  cg20826792  ...  cg17939569  cg13365400  \\\n",
       "0     0.748790    0.131226    0.131664  ...         NaN         NaN   \n",
       "1     0.737550    0.225267    0.213943  ...    0.741882    0.607857   \n",
       "2     0.548639    0.126281    0.118666  ...    0.227705    0.235356   \n",
       "3     0.587720    0.091899    0.120725  ...    0.815071    0.513299   \n",
       "4     0.641742    0.245444    0.265556  ...         NaN         NaN   \n",
       "5     0.626692    0.114128    0.112664  ...    0.750602    0.473561   \n",
       "6     0.669206    0.105999    0.162168  ...         NaN         NaN   \n",
       "7     0.609909    0.126268    0.186922  ...    0.230692    0.227732   \n",
       "8     0.721725    0.137078    0.113993  ...    0.222673         NaN   \n",
       "9     0.735287    0.077172    0.130759  ...    0.768983    0.529242   \n",
       "10    0.677905    0.101623    0.158239  ...    0.600804    0.413791   \n",
       "11    0.670722    0.122745    0.167697  ...    0.254087         NaN   \n",
       "12    0.627448    0.122829    0.164834  ...    0.771967    0.513431   \n",
       "13    0.677762    0.127385    0.135253  ...         NaN         NaN   \n",
       "14    0.661538    0.123618    0.147830  ...         NaN    0.256320   \n",
       "15    0.682771    0.100978    0.145999  ...    0.671044    0.478505   \n",
       "16    0.638250    0.119335    0.158341  ...         NaN         NaN   \n",
       "17    0.600773    0.096311    0.137092  ...    0.762447    0.477126   \n",
       "18    0.600399    0.101740    0.103942  ...    0.801542    0.563342   \n",
       "19    0.606477    0.110302    0.092445  ...    0.765222    0.640587   \n",
       "20    0.540110    0.107610    0.132012  ...         NaN         NaN   \n",
       "21    0.614475    0.066072    0.131415  ...    0.742420    0.469953   \n",
       "22    0.613343    0.089275    0.105144  ...         NaN         NaN   \n",
       "23    0.666121    0.099218    0.097875  ...    0.789760    0.543899   \n",
       "24    0.643749    0.098625    0.105695  ...    0.788581    0.527433   \n",
       "25    0.598383    0.239695    0.258341  ...    0.812545    0.555426   \n",
       "26    0.762719    0.148420    0.119298  ...         NaN         NaN   \n",
       "27    0.598144    0.098938    0.110624  ...         NaN    0.236782   \n",
       "28    0.555251    0.112228    0.146407  ...         NaN         NaN   \n",
       "29    0.646664    0.230900    0.230941  ...         NaN         NaN   \n",
       "\n",
       "    cg02600718  cg21106100  cg08265308  cg10488260  cg14273923  cg09748881  \\\n",
       "0     0.204499    0.233191    0.410137    0.116070    0.238445         NaN   \n",
       "1     0.247206    0.637003    0.849188    0.504236    0.440615    0.823711   \n",
       "2     0.231018    0.234811    0.420113    0.139597    0.223410    0.199689   \n",
       "3     0.249403    0.745385    0.924718    0.591618    0.713801    0.852716   \n",
       "4     0.261898    0.229423    0.438345    0.211108         NaN         NaN   \n",
       "5     0.227851    0.899750    0.924760    0.391456    0.810127    0.746885   \n",
       "6     0.246564    0.253218    0.412819    0.138194         NaN    0.216414   \n",
       "7     0.254356    0.225905    0.389093    0.189091         NaN         NaN   \n",
       "8          NaN    0.219803    0.463869    0.168533    0.245503         NaN   \n",
       "9     0.219134    0.804604    0.930088    0.538191    0.855217    0.764714   \n",
       "10    0.232792    0.878060    0.934445    0.405269    0.762313    0.778833   \n",
       "11    0.216899    0.228183    0.420426    0.137345    0.224384    0.228634   \n",
       "12    0.232924    0.862327    0.920467    0.367181    0.664971    0.814897   \n",
       "13         NaN    0.205848    0.453384    0.137929    0.229974    0.233784   \n",
       "14    0.314065    0.223014    0.385513    0.100546         NaN         NaN   \n",
       "15    0.260438    0.850432    0.902303    0.276911    0.606481    0.749622   \n",
       "16    0.282263    0.214288    0.432736    0.136878         NaN         NaN   \n",
       "17    0.350102    0.845531    0.921718    0.316076    0.739091    0.754490   \n",
       "18    0.255242    0.858453    0.927807    0.570651    0.711534    0.842075   \n",
       "19    0.203927    0.770290    0.958099    0.477990    0.518595    0.829578   \n",
       "20    0.232594    0.217625    0.461653    0.204903         NaN         NaN   \n",
       "21    0.249524    0.905930    0.934995    0.515482    0.841846    0.780279   \n",
       "22    0.234089    0.229211    0.451202    0.127532         NaN    0.208099   \n",
       "23    0.265834    0.906830    0.912564    0.374315    0.725956    0.839753   \n",
       "24    0.297396    0.868786    0.877040    0.603917    0.799931    0.838740   \n",
       "25    0.273489    0.772869    0.898933    0.388806    0.653115    0.768496   \n",
       "26         NaN    0.231941    0.433197    0.141837         NaN         NaN   \n",
       "27    0.219070    0.251683    0.461159    0.135706    0.231465         NaN   \n",
       "28    0.238849    0.246116    0.430747    0.156751    0.234477         NaN   \n",
       "29         NaN    0.237234         NaN    0.145440         NaN         NaN   \n",
       "\n",
       "    cg07587934  cg16855331  \n",
       "0     0.806420    0.415945  \n",
       "1     0.777729    0.567635  \n",
       "2     0.807111    0.493500  \n",
       "3     0.782532    0.491458  \n",
       "4     0.815358    0.434790  \n",
       "5     0.818290    0.505662  \n",
       "6     0.823519    0.465784  \n",
       "7     0.798229    0.417867  \n",
       "8     0.851469    0.416282  \n",
       "9     0.817391    0.626756  \n",
       "10    0.755422    0.394690  \n",
       "11    0.765352    0.416575  \n",
       "12    0.795508    0.462717  \n",
       "13    0.828704    0.429640  \n",
       "14    0.746832    0.412882  \n",
       "15    0.713177    0.393546  \n",
       "16    0.806033    0.390286  \n",
       "17    0.812482    0.448128  \n",
       "18    0.705437    0.521170  \n",
       "19    0.829165    0.578922  \n",
       "20    0.798377    0.418920  \n",
       "21    0.768973    0.451674  \n",
       "22    0.853916    0.466294  \n",
       "23    0.775440    0.495858  \n",
       "24    0.803204    0.451297  \n",
       "25    0.716652    0.449627  \n",
       "26    0.829540    0.565420  \n",
       "27    0.825574    0.429536  \n",
       "28    0.798229    0.457896  \n",
       "29    0.605348    0.688054  \n",
       "\n",
       "[30 rows x 865862 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "methylome.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "methylome = methylome.drop(\"idBiospe\", axis=1)\n",
    "methylome = methylome.drop(\"timePoint\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>cg14817997</th>\n",
       "      <th>cg26928153</th>\n",
       "      <th>cg16269199</th>\n",
       "      <th>cg13869341</th>\n",
       "      <th>cg14008030</th>\n",
       "      <th>cg12045430</th>\n",
       "      <th>cg20826792</th>\n",
       "      <th>cg20253340</th>\n",
       "      <th>cg02404219</th>\n",
       "      <th>...</th>\n",
       "      <th>cg17939569</th>\n",
       "      <th>cg13365400</th>\n",
       "      <th>cg02600718</th>\n",
       "      <th>cg21106100</th>\n",
       "      <th>cg08265308</th>\n",
       "      <th>cg10488260</th>\n",
       "      <th>cg14273923</th>\n",
       "      <th>cg09748881</th>\n",
       "      <th>cg07587934</th>\n",
       "      <th>cg16855331</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0.370702</td>\n",
       "      <td>0.906810</td>\n",
       "      <td>0.729572</td>\n",
       "      <td>0.919086</td>\n",
       "      <td>0.748790</td>\n",
       "      <td>0.131226</td>\n",
       "      <td>0.131664</td>\n",
       "      <td>0.672684</td>\n",
       "      <td>0.675035</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.204499</td>\n",
       "      <td>0.233191</td>\n",
       "      <td>0.410137</td>\n",
       "      <td>0.116070</td>\n",
       "      <td>0.238445</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.806420</td>\n",
       "      <td>0.415945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.352146</td>\n",
       "      <td>0.475196</td>\n",
       "      <td>0.227495</td>\n",
       "      <td>0.772063</td>\n",
       "      <td>0.737550</td>\n",
       "      <td>0.225267</td>\n",
       "      <td>0.213943</td>\n",
       "      <td>0.688005</td>\n",
       "      <td>0.659342</td>\n",
       "      <td>...</td>\n",
       "      <td>0.741882</td>\n",
       "      <td>0.607857</td>\n",
       "      <td>0.247206</td>\n",
       "      <td>0.637003</td>\n",
       "      <td>0.849188</td>\n",
       "      <td>0.504236</td>\n",
       "      <td>0.440615</td>\n",
       "      <td>0.823711</td>\n",
       "      <td>0.777729</td>\n",
       "      <td>0.567635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.307659</td>\n",
       "      <td>0.872990</td>\n",
       "      <td>0.657483</td>\n",
       "      <td>0.819911</td>\n",
       "      <td>0.548639</td>\n",
       "      <td>0.126281</td>\n",
       "      <td>0.118666</td>\n",
       "      <td>0.791500</td>\n",
       "      <td>0.813271</td>\n",
       "      <td>...</td>\n",
       "      <td>0.227705</td>\n",
       "      <td>0.235356</td>\n",
       "      <td>0.231018</td>\n",
       "      <td>0.234811</td>\n",
       "      <td>0.420113</td>\n",
       "      <td>0.139597</td>\n",
       "      <td>0.223410</td>\n",
       "      <td>0.199689</td>\n",
       "      <td>0.807111</td>\n",
       "      <td>0.493500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.369779</td>\n",
       "      <td>0.875169</td>\n",
       "      <td>0.725316</td>\n",
       "      <td>0.909891</td>\n",
       "      <td>0.587720</td>\n",
       "      <td>0.091899</td>\n",
       "      <td>0.120725</td>\n",
       "      <td>0.561473</td>\n",
       "      <td>0.782631</td>\n",
       "      <td>...</td>\n",
       "      <td>0.815071</td>\n",
       "      <td>0.513299</td>\n",
       "      <td>0.249403</td>\n",
       "      <td>0.745385</td>\n",
       "      <td>0.924718</td>\n",
       "      <td>0.591618</td>\n",
       "      <td>0.713801</td>\n",
       "      <td>0.852716</td>\n",
       "      <td>0.782532</td>\n",
       "      <td>0.491458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.325455</td>\n",
       "      <td>0.826068</td>\n",
       "      <td>0.612782</td>\n",
       "      <td>0.738983</td>\n",
       "      <td>0.641742</td>\n",
       "      <td>0.245444</td>\n",
       "      <td>0.265556</td>\n",
       "      <td>0.743723</td>\n",
       "      <td>0.654437</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.261898</td>\n",
       "      <td>0.229423</td>\n",
       "      <td>0.438345</td>\n",
       "      <td>0.211108</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.815358</td>\n",
       "      <td>0.434790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>0.335254</td>\n",
       "      <td>0.859299</td>\n",
       "      <td>0.720324</td>\n",
       "      <td>0.859915</td>\n",
       "      <td>0.626692</td>\n",
       "      <td>0.114128</td>\n",
       "      <td>0.112664</td>\n",
       "      <td>0.792145</td>\n",
       "      <td>0.728729</td>\n",
       "      <td>...</td>\n",
       "      <td>0.750602</td>\n",
       "      <td>0.473561</td>\n",
       "      <td>0.227851</td>\n",
       "      <td>0.899750</td>\n",
       "      <td>0.924760</td>\n",
       "      <td>0.391456</td>\n",
       "      <td>0.810127</td>\n",
       "      <td>0.746885</td>\n",
       "      <td>0.818290</td>\n",
       "      <td>0.505662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2</td>\n",
       "      <td>0.554714</td>\n",
       "      <td>0.881504</td>\n",
       "      <td>0.687885</td>\n",
       "      <td>0.851117</td>\n",
       "      <td>0.669206</td>\n",
       "      <td>0.105999</td>\n",
       "      <td>0.162168</td>\n",
       "      <td>0.708349</td>\n",
       "      <td>0.855416</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.246564</td>\n",
       "      <td>0.253218</td>\n",
       "      <td>0.412819</td>\n",
       "      <td>0.138194</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.216414</td>\n",
       "      <td>0.823519</td>\n",
       "      <td>0.465784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0.665123</td>\n",
       "      <td>0.936929</td>\n",
       "      <td>0.773192</td>\n",
       "      <td>0.832327</td>\n",
       "      <td>0.609909</td>\n",
       "      <td>0.126268</td>\n",
       "      <td>0.186922</td>\n",
       "      <td>0.701086</td>\n",
       "      <td>0.870693</td>\n",
       "      <td>...</td>\n",
       "      <td>0.230692</td>\n",
       "      <td>0.227732</td>\n",
       "      <td>0.254356</td>\n",
       "      <td>0.225905</td>\n",
       "      <td>0.389093</td>\n",
       "      <td>0.189091</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.798229</td>\n",
       "      <td>0.417867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0.369006</td>\n",
       "      <td>0.864040</td>\n",
       "      <td>0.693321</td>\n",
       "      <td>0.847711</td>\n",
       "      <td>0.721725</td>\n",
       "      <td>0.137078</td>\n",
       "      <td>0.113993</td>\n",
       "      <td>0.890438</td>\n",
       "      <td>0.599843</td>\n",
       "      <td>...</td>\n",
       "      <td>0.222673</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.219803</td>\n",
       "      <td>0.463869</td>\n",
       "      <td>0.168533</td>\n",
       "      <td>0.245503</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.851469</td>\n",
       "      <td>0.416282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2</td>\n",
       "      <td>0.309475</td>\n",
       "      <td>0.605469</td>\n",
       "      <td>0.559015</td>\n",
       "      <td>0.853587</td>\n",
       "      <td>0.735287</td>\n",
       "      <td>0.077172</td>\n",
       "      <td>0.130759</td>\n",
       "      <td>0.701003</td>\n",
       "      <td>0.461794</td>\n",
       "      <td>...</td>\n",
       "      <td>0.768983</td>\n",
       "      <td>0.529242</td>\n",
       "      <td>0.219134</td>\n",
       "      <td>0.804604</td>\n",
       "      <td>0.930088</td>\n",
       "      <td>0.538191</td>\n",
       "      <td>0.855217</td>\n",
       "      <td>0.764714</td>\n",
       "      <td>0.817391</td>\n",
       "      <td>0.626756</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 865860 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   class  cg14817997  cg26928153  cg16269199  cg13869341  cg14008030  \\\n",
       "0      2    0.370702    0.906810    0.729572    0.919086    0.748790   \n",
       "1      2    0.352146    0.475196    0.227495    0.772063    0.737550   \n",
       "2      1    0.307659    0.872990    0.657483    0.819911    0.548639   \n",
       "3      0    0.369779    0.875169    0.725316    0.909891    0.587720   \n",
       "4      0    0.325455    0.826068    0.612782    0.738983    0.641742   \n",
       "5      1    0.335254    0.859299    0.720324    0.859915    0.626692   \n",
       "6      2    0.554714    0.881504    0.687885    0.851117    0.669206   \n",
       "7      0    0.665123    0.936929    0.773192    0.832327    0.609909   \n",
       "8      0    0.369006    0.864040    0.693321    0.847711    0.721725   \n",
       "9      2    0.309475    0.605469    0.559015    0.853587    0.735287   \n",
       "\n",
       "   cg12045430  cg20826792  cg20253340  cg02404219  ...  cg17939569  \\\n",
       "0    0.131226    0.131664    0.672684    0.675035  ...         NaN   \n",
       "1    0.225267    0.213943    0.688005    0.659342  ...    0.741882   \n",
       "2    0.126281    0.118666    0.791500    0.813271  ...    0.227705   \n",
       "3    0.091899    0.120725    0.561473    0.782631  ...    0.815071   \n",
       "4    0.245444    0.265556    0.743723    0.654437  ...         NaN   \n",
       "5    0.114128    0.112664    0.792145    0.728729  ...    0.750602   \n",
       "6    0.105999    0.162168    0.708349    0.855416  ...         NaN   \n",
       "7    0.126268    0.186922    0.701086    0.870693  ...    0.230692   \n",
       "8    0.137078    0.113993    0.890438    0.599843  ...    0.222673   \n",
       "9    0.077172    0.130759    0.701003    0.461794  ...    0.768983   \n",
       "\n",
       "   cg13365400  cg02600718  cg21106100  cg08265308  cg10488260  cg14273923  \\\n",
       "0         NaN    0.204499    0.233191    0.410137    0.116070    0.238445   \n",
       "1    0.607857    0.247206    0.637003    0.849188    0.504236    0.440615   \n",
       "2    0.235356    0.231018    0.234811    0.420113    0.139597    0.223410   \n",
       "3    0.513299    0.249403    0.745385    0.924718    0.591618    0.713801   \n",
       "4         NaN    0.261898    0.229423    0.438345    0.211108         NaN   \n",
       "5    0.473561    0.227851    0.899750    0.924760    0.391456    0.810127   \n",
       "6         NaN    0.246564    0.253218    0.412819    0.138194         NaN   \n",
       "7    0.227732    0.254356    0.225905    0.389093    0.189091         NaN   \n",
       "8         NaN         NaN    0.219803    0.463869    0.168533    0.245503   \n",
       "9    0.529242    0.219134    0.804604    0.930088    0.538191    0.855217   \n",
       "\n",
       "   cg09748881  cg07587934  cg16855331  \n",
       "0         NaN    0.806420    0.415945  \n",
       "1    0.823711    0.777729    0.567635  \n",
       "2    0.199689    0.807111    0.493500  \n",
       "3    0.852716    0.782532    0.491458  \n",
       "4         NaN    0.815358    0.434790  \n",
       "5    0.746885    0.818290    0.505662  \n",
       "6    0.216414    0.823519    0.465784  \n",
       "7         NaN    0.798229    0.417867  \n",
       "8         NaN    0.851469    0.416282  \n",
       "9    0.764714    0.817391    0.626756  \n",
       "\n",
       "[10 rows x 865860 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "methylome.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(219, 865860)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "methylome.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\arian\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xgboost\\core.py:160: UserWarning: [23:53:41] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"predictor\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "\n",
    "# Separate features and target\n",
    "X = methylome.drop('class', axis=1)\n",
    "y = methylome['class']\n",
    "\n",
    "# Re-encode the labels in the target variable\n",
    "encoder = LabelEncoder()\n",
    "y = encoder.fit_transform(y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "dtest = xgb.DMatrix(X_test, label=y_test)\n",
    "\n",
    "# param tuning\n",
    "params = {\n",
    "    'tree_method': 'hist',  # Use GPU accelerated algorithm\n",
    "    'predictor': 'gpu_predictor',  # Use GPU for prediction\n",
    "    'device': 'cuda',  # Use CUDA for GPU acceleration\n",
    "    'max_depth':10,\n",
    "    'eta': 0.2,\n",
    "    'objective': 'multi:softmax',\n",
    "    'num_class': 4  # Number of unique classes in the target variable\n",
    "}\n",
    "\n",
    "epochs=10\n",
    "model = xgb.train(params, dtrain,epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(dtest)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.25\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Compute accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 10 Most Important Features:\n",
      "cg14817997: 2.0\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA90AAAJOCAYAAACqS2TfAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8g+/7EAAAACXBIWXMAAA9hAAAPYQGoP6dpAABNd0lEQVR4nO3deVxWZf7/8fcNyiIKSspmqLikqSCGRm6ZRSKZZU6uzYjk8stpGSMrsERxwywdNbdKjSz3FpxJoxzKLDXNrVLTEcNcAlxSEPwKCuf3R+Ndd6ByK8db8PV8PM5jPNd1net8zu08HjNvr7NYDMMwBAAAAAAAyp2TowsAAAAAAKCyInQDAAAAAGASQjcAAAAAACYhdAMAAAAAYBJCNwAAAAAAJiF0AwAAAABgEkI3AAAAAAAmIXQDAAAAAGASQjcAAAAAACYhdAMAAAAAYBJCNwDgppCcnCyLxVLqFhcXZ8o5N27cqLFjx+r06dOmzH8tLv4eW7dudXQpV23OnDlKTk52dBkAAFxWFUcXAADA9TRu3DgFBQXZtLVs2dKUc23cuFGJiYkaNGiQatasaco5bmZz5sxR7dq1NWjQIEeXAgDAJRG6AQA3laioKLVp08bRZVyT/Px8eXh4OLoMhzl79qyqVavm6DIAACgTbi8HAOAPPvnkE3Xq1EkeHh6qUaOGunfvrt27d9uM+f777zVo0CA1bNhQbm5u8vPz0+OPP66TJ09ax4wdO1bPP/+8JCkoKMh6K/vBgwd18OBBWSyWUm+NtlgsGjt2rM08FotFe/bs0YABA1SrVi117NjR2v/ee+8pLCxM7u7u8vb2Vr9+/XT48OGruvZBgwapevXqOnTokB588EFVr15ddevW1ezZsyVJP/zwg+699155eHiofv36WrJkic3xF29ZX79+vf7f//t/uuWWW+Tp6amBAwfq1KlTJc43Z84ctWjRQq6urgoICNCTTz5Z4lb8e+65Ry1bttS2bdt09913q1q1aho1apQaNGig3bt368svv7T+tvfcc48k6ddff9XIkSMVHBys6tWry9PTU1FRUfruu+9s5l63bp0sFotWrFihiRMn6tZbb5Wbm5vuu+8+paenl6h38+bNeuCBB1SrVi15eHgoJCREM2bMsBmzd+9ePfroo/L29pabm5vatGmjf/3rX/b+VQAAKhFWugEAN5WcnBydOHHCpq127dqSpHfffVfR0dGKjIzUK6+8orNnz2ru3Lnq2LGjduzYoQYNGkiS1q5dq59++kkxMTHy8/PT7t279eabb2r37t365ptvZLFY1KtXL/33v//V0qVL9c9//tN6jjp16uj48eN21927d281adJEkyZNkmEYkqSJEydq9OjR6tOnj4YMGaLjx4/r9ddf1913360dO3Zc1S3tRUVFioqK0t13360pU6Zo8eLFeuqpp+Th4aGXXnpJjz32mHr16qV58+Zp4MCBateuXYnb9Z966inVrFlTY8eO1b59+zR37lz9/PPP1pAr/faPCYmJiYqIiNDw4cOt47799ltt2LBBVatWtc538uRJRUVFqV+/fvrrX/8qX19f3XPPPXr66adVvXp1vfTSS5IkX19fSdJPP/2klJQU9e7dW0FBQcrOztYbb7yhzp07a8+ePQoICLCpd/LkyXJyctLIkSOVk5OjKVOm6LHHHtPmzZutY9auXasHH3xQ/v7++sc//iE/Pz/9+OOP+vjjj/WPf/xDkrR792516NBBdevWVVxcnDw8PLRixQr17NlTH3zwgR555BG7/z4AAJWAAQDATeDtt982JJW6GYZhnDlzxqhZs6YxdOhQm+OysrIMLy8vm/azZ8+WmH/p0qWGJGP9+vXWtldffdWQZGRkZNiMzcjIMCQZb7/9dol5JBljxoyx7o8ZM8aQZPTv399m3MGDBw1nZ2dj4sSJNu0//PCDUaVKlRLtl/o9vv32W2tbdHS0IcmYNGmSte3UqVOGu7u7YbFYjGXLllnb9+7dW6LWi3OGhYUZhYWF1vYpU6YYkoxVq1YZhmEYx44dM1xcXIyuXbsaRUVF1nGzZs0yJBkLFy60tnXu3NmQZMybN6/ENbRo0cLo3LlzifZz587ZzGsYv/3mrq6uxrhx46xtX3zxhSHJuP32242CggJr+4wZMwxJxg8//GAYhmFcuHDBCAoKMurXr2+cOnXKZt7i4mLrn++77z4jODjYOHfunE1/+/btjSZNmpSoEwBwc+D2cgDATWX27Nlau3atzSb9tpJ5+vRp9e/fXydOnLBuzs7OCg8P1xdffGGdw93d3frnc+fO6cSJE7rrrrskSdu3bzel7ieeeMJm/8MPP1RxcbH69OljU6+fn5+aNGliU6+9hgwZYv1zzZo11bRpU3l4eKhPnz7W9qZNm6pmzZr66aefShw/bNgwm5Xq4cOHq0qVKlqzZo0k6T//+Y8KCws1YsQIOTn9/n9Fhg4dKk9PT61evdpmPldXV8XExJS5fldXV+u8RUVFOnnypKpXr66mTZuW+vcTExMjFxcX636nTp0kyXptO3bsUEZGhkaMGFHi7oGLK/e//vqrPv/8c/Xp00dnzpyx/n2cPHlSkZGR2r9/v44ePVrmawAAVB7cXg4AuKnceeedpb5Ibf/+/ZKke++9t9TjPD09rX/+9ddflZiYqGXLlunYsWM243Jycsqx2t/9+Rbu/fv3yzAMNWnSpNTxfwy99nBzc1OdOnVs2ry8vHTrrbdaA+Yf20t7VvvPNVWvXl3+/v46ePCgJOnnn3+W9Ftw/yMXFxc1bNjQ2n9R3bp1bULxlRQXF2vGjBmaM2eOMjIyVFRUZO275ZZbSoyvV6+ezX6tWrUkyXptBw4ckHT5t9ynp6fLMAyNHj1ao0ePLnXMsWPHVLdu3TJfBwCgciB0AwCg34Ka9Ntz3X5+fiX6q1T5/X8y+/Tpo40bN+r5559XaGioqlevruLiYnXr1s06z+X8Obxe9Mdw+Gd/XF2/WK/FYtEnn3wiZ2fnEuOrV69+xTpKU9pcl2s3/vd8uZn+fO1XMmnSJI0ePVqPP/64xo8fL29vbzk5OWnEiBGl/v2Ux7VdnHfkyJGKjIwsdUzjxo3LPB8AoPIgdAMAIKlRo0aSJB8fH0VERFxy3KlTp5SWlqbExEQlJCRY2y+ulP/RpcL1xZXUP7+p+88rvFeq1zAMBQUF6bbbbivzcdfD/v371aVLF+t+Xl6eMjMz9cADD0iS6tevL0nat2+fGjZsaB1XWFiojIyMy/7+f3Sp3/f9999Xly5dtGDBApv206dPW19oZ4+L/93YtWvXJWu7eB1Vq1Ytc/0AgJsDz3QDACApMjJSnp6emjRpks6fP1+i/+Ibxy+uiv55FXT69Okljrn4Le0/h2tPT0/Vrl1b69evt2mfM2dOmevt1auXnJ2dlZiYWKIWwzBsPl92vb355ps2v+HcuXN14cIFRUVFSZIiIiLk4uKimTNn2tS+YMEC5eTkqHv37mU6j4eHR4nfVvrt7+jPv8nKlSuv+pnqO+64Q0FBQZo+fXqJ8108j4+Pj+655x698cYbyszMLDHH1byxHgBQObDSDQCAfgvCc+fO1d/+9jfdcccd6tevn+rUqaNDhw5p9erV6tChg2bNmiVPT0/r57TOnz+vunXr6rPPPlNGRkaJOcPCwiRJL730kvr166eqVauqR48e8vDw0JAhQzR58mQNGTJEbdq00fr16/Xf//63zPU2atRIEyZMUHx8vA4ePKiePXuqRo0aysjI0EcffaRhw4Zp5MiR5fb72KOwsFD33Xef+vTpo3379mnOnDnq2LGjHnroIUm/fTYtPj5eiYmJ6tatmx566CHruLZt2+qvf/1rmc4TFhamuXPnasKECWrcuLF8fHx077336sEHH9S4ceMUExOj9u3b64cfftDixYttVtXt4eTkpLlz56pHjx4KDQ1VTEyM/P39tXfvXu3evVuffvqppN9e0texY0cFBwdr6NChatiwobKzs7Vp0yYdOXKkxHfCAQA3B0I3AAD/M2DAAAUEBGjy5Ml69dVXVVBQoLp166pTp042b89esmSJnn76ac2ePVuGYahr16765JNPSnz/uW3btho/frzmzZun1NRUFRcXKyMjQx4eHkpISNDx48f1/vvva8WKFYqKitInn3wiHx+fMtcbFxen2267Tf/85z+VmJgoSQoMDFTXrl2tAdcRZs2apcWLFyshIUHnz59X//79NXPmTJvbwceOHas6depo1qxZevbZZ+Xt7a1hw4Zp0qRJZX4JXEJCgn7++WdNmTJFZ86cUefOnXXvvfdq1KhRys/P15IlS7R8+XLdcccdWr16teLi4q76miIjI/XFF18oMTFRU6dOVXFxsRo1aqShQ4daxzRv3lxbt25VYmKikpOTdfLkSfn4+Kh169Y2jyIAAG4uFuN6vAEFAABUesnJyYqJidG3335b6hviAQC4GfFMNwAAAAAAJiF0AwAAAABgEkI3AAAAAAAm4ZluAAAAAABMwko3AAAAAAAmIXQDAAAAAGASvtNdiuLiYv3yyy+qUaOGzTdFAQAAAACQJMMwdObMGQUEBMjJ6dLr2YTuUvzyyy8KDAx0dBkAAAAAgBvc4cOHdeutt16yn9Bdiho1akj67cfz9PR0cDUAAAAAgBtNbm6uAgMDrfnxUgjdpbh4S7mnpyehGwAAAABwSVd6JJkXqQEAAAAAYBJCNwAAAAAAJiF0AwAAAABgEkI3AAAAAAAmIXQDAAAAAGASQjcAAAAAACYhdAMAAAAAYBJCNwAAAAAAJiF0AwAAAABgEkI3AAAAAAAmIXQDAAAAAGASQjcAAAAAACYhdAMAAAAAYBJCNwAAAAAAJiF0AwAAAABgEkI3AAAAAAAmIXQDAAAAAGASh4bupKQktW3bVjVq1JCPj4969uypffv2XfG4lStXqlmzZnJzc1NwcLDWrFlj028YhhISEuTv7y93d3dFRERo//79Zl0GAAAAAAClcmjo/vLLL/Xkk0/qm2++0dq1a3X+/Hl17dpV+fn5lzxm48aN6t+/vwYPHqwdO3aoZ8+e6tmzp3bt2mUdM2XKFM2cOVPz5s3T5s2b5eHhocjISJ07d+56XBYAAAAAAJIki2EYhqOLuOj48ePy8fHRl19+qbvvvrvUMX379lV+fr4+/vhja9tdd92l0NBQzZs3T4ZhKCAgQM8995xGjhwpScrJyZGvr6+Sk5PVr1+/K9aRm5srLy8v5eTkyNPTs3wuDgAAAABQaZQ1N95Qz3Tn5ORIkry9vS85ZtOmTYqIiLBpi4yM1KZNmyRJGRkZysrKshnj5eWl8PBw65g/KygoUG5urs0GAAAAAMC1quLoAi4qLi7WiBEj1KFDB7Vs2fKS47KysuTr62vT5uvrq6ysLGv/xbZLjfmzpKQkJSYmXkv5DtEgbrWjSwAAAAAAUxyc3N3RJZSLG2al+8knn9SuXbu0bNmy637u+Ph45eTkWLfDhw9f9xoAAAAAAJXPDbHS/dRTT+njjz/W+vXrdeutt152rJ+fn7Kzs23asrOz5efnZ+2/2Obv728zJjQ0tNQ5XV1d5erqeg1XAAAAAABASQ5d6TYMQ0899ZQ++ugjff755woKCrriMe3atVNaWppN29q1a9WuXTtJUlBQkPz8/GzG5ObmavPmzdYxAAAAAABcDw5d6X7yySe1ZMkSrVq1SjVq1LA+c+3l5SV3d3dJ0sCBA1W3bl0lJSVJkv7xj3+oc+fOmjp1qrp3765ly5Zp69atevPNNyVJFotFI0aM0IQJE9SkSRMFBQVp9OjRCggIUM+ePR1ynQAAAACAm5NDQ/fcuXMlSffcc49N+9tvv61BgwZJkg4dOiQnp98X5Nu3b68lS5bo5Zdf1qhRo9SkSROlpKTYvHzthRdeUH5+voYNG6bTp0+rY8eOSk1NlZubm+nXBAAAAADARTfUd7pvFBXlO928vRwAAABAZXWjv728Qn6nGwAAAACAyoTQDQAAAACASQjdAAAAAACYhNANAAAAAIBJCN0AAAAAAJiE0A0AAAAAgEkI3QAAAAAAmITQDQAAAACASQjdAAAAAACYhNANAAAAAIBJCN0AAAAAAJiE0A0AAAAAgEkI3QAAAAAAmITQDQAAAACASQjdAAAAAACYhNANAAAAAIBJCN0AAAAAAJiE0A0AAAAAgEkI3QAAAAAAmITQDQAAAACASQjdAAAAAACYhNANAAAAAIBJCN0AAAAAAJiE0A0AAAAAgEkI3QAAAAAAmITQDQAAAACASQjdAAAAAACYhNANAAAAAIBJCN0AAAAAAJiE0A0AAAAAgEkI3QAAAAAAmITQDQAAAACASQjdAAAAAACYhNANAAAAAIBJCN0AAAAAAJiE0A0AAAAAgEkI3QAAAAAAmITQDQAAAACASQjdAAAAAACYhNANAAAAAIBJCN0AAAAAAJiE0A0AAAAAgEkI3QAAAAAAmITQDQAAAACASQjdAAAAAACYhNANAAAAAIBJCN0AAAAAAJiE0A0AAAAAgEkI3QAAAAAAmMShoXv9+vXq0aOHAgICZLFYlJKSctnxgwYNksViKbG1aNHCOmbs2LEl+ps1a2bylQAAAAAAUJJDQ3d+fr5atWql2bNnl2n8jBkzlJmZad0OHz4sb29v9e7d22ZcixYtbMZ9/fXXZpQPAAAAAMBlVXHkyaOiohQVFVXm8V5eXvLy8rLup6Sk6NSpU4qJibEZV6VKFfn5+ZVbnQAAAAAAXI0K/Uz3ggULFBERofr169u079+/XwEBAWrYsKEee+wxHTp06LLzFBQUKDc312YDAAAAAOBaVdjQ/csvv+iTTz7RkCFDbNrDw8OVnJys1NRUzZ07VxkZGerUqZPOnDlzybmSkpKsq+heXl4KDAw0u3wAAAAAwE2gwobud955RzVr1lTPnj1t2qOiotS7d2+FhIQoMjJSa9as0enTp7VixYpLzhUfH6+cnBzrdvjwYZOrBwAAAADcDBz6TPfVMgxDCxcu1N/+9je5uLhcdmzNmjV12223KT09/ZJjXF1d5erqWt5lAgAAAABuchVypfvLL79Uenq6Bg8efMWxeXl5OnDggPz9/a9DZQAAAAAA/M6hoTsvL087d+7Uzp07JUkZGRnauXOn9cVn8fHxGjhwYInjFixYoPDwcLVs2bJE38iRI/Xll1/q4MGD2rhxox555BE5Ozurf//+pl4LAAAAAAB/5tDby7du3aouXbpY92NjYyVJ0dHRSk5OVmZmZok3j+fk5OiDDz7QjBkzSp3zyJEj6t+/v06ePKk6deqoY8eO+uabb1SnTh3zLgQAAAAAgFJYDMMwHF3EjSY3N1deXl7KycmRp6eno8u5pAZxqx1dAgAAAACY4uDk7o4u4bLKmhsr5DPdAAAAAABUBIRuAAAAAABMQugGAAAAAMAkhG4AAAAAAExC6AYAAAAAwCSEbgAAAAAATELoBgAAAADAJIRuAAAAAABMQugGAAAAAMAkhG4AAAAAAExC6AYAAAAAwCSEbgAAAAAATELoBgAAAADAJIRuAAAAAABMQugGAAAAAMAkhG4AAAAAAExC6AYAAAAAwCSEbgAAAAAATELoBgAAAADAJIRuAAAAAABMQugGAAAAAMAkhG4AAAAAAExC6AYAAAAAwCSEbgAAAAAATELoBgAAAADAJIRuAAAAAABMQugGAAAAAMAkhG4AAAAAAExC6AYAAAAAwCSEbgAAAAAATELoBgAAAADAJIRuAAAAAABMQugGAAAAAMAkhG4AAAAAAExC6AYAAAAAwCSEbgAAAAAATELoBgAAAADAJIRuAAAAAABMQugGAAAAAMAkhG4AAAAAAExC6AYAAAAAwCSEbgAAAAAATELoBgAAAADAJIRuAAAAAABMQugGAAAAAMAkhG4AAAAAAExC6AYAAAAAwCSEbgAAAAAATELoBgAAAADAJA4N3evXr1ePHj0UEBAgi8WilJSUy45ft26dLBZLiS0rK8tm3OzZs9WgQQO5ubkpPDxcW7ZsMfEqAAAAAAAonUNDd35+vlq1aqXZs2fbddy+ffuUmZlp3Xx8fKx9y5cvV2xsrMaMGaPt27erVatWioyM1LFjx8q7fAAAAAAALquKI08eFRWlqKgou4/z8fFRzZo1S+2bNm2ahg4dqpiYGEnSvHnztHr1ai1cuFBxcXHXUi4AAAAAAHapkM90h4aGyt/fX/fff782bNhgbS8sLNS2bdsUERFhbXNyclJERIQ2bdp0yfkKCgqUm5trswEAAAAAcK0qVOj29/fXvHnz9MEHH+iDDz5QYGCg7rnnHm3fvl2SdOLECRUVFcnX19fmOF9f3xLPff9RUlKSvLy8rFtgYKCp1wEAAAAAuDk49PZyezVt2lRNmza17rdv314HDhzQP//5T7377rtXPW98fLxiY2Ot+7m5uQRvAAAAAMA1q1ChuzR33nmnvv76a0lS7dq15ezsrOzsbJsx2dnZ8vPzu+Qcrq6ucnV1NbVOAAAAAMDNp0LdXl6anTt3yt/fX5Lk4uKisLAwpaWlWfuLi4uVlpamdu3aOapEAAAAAMBNyqEr3Xl5eUpPT7fuZ2RkaOfOnfL29la9evUUHx+vo0ePatGiRZKk6dOnKygoSC1atNC5c+c0f/58ff755/rss8+sc8TGxio6Olpt2rTRnXfeqenTpys/P9/6NnMAAAAAAK4Xh4burVu3qkuXLtb9i89VR0dHKzk5WZmZmTp06JC1v7CwUM8995yOHj2qatWqKSQkRP/5z39s5ujbt6+OHz+uhIQEZWVlKTQ0VKmpqSVergYAAAAAgNkshmEYji7iRpObmysvLy/l5OTI09PT0eVcUoO41Y4uAQAAAABMcXByd0eXcFllzY0V/pluAAAAAABuVIRuAAAAAABMQugGAAAAAMAkhG4AAAAAAExC6AYAAAAAwCSEbgAAAAAATELoBgAAAADAJIRuAAAAAABMQugGAAAAAMAkhG4AAAAAAExC6AYAAAAAwCSEbgAAAAAATELoBgAAAADAJIRuAAAAAABMQugGAAAAAMAkhG4AAAAAAExC6AYAAAAAwCSEbgAAAAAATELoBgAAAADAJIRuAAAAAABMQugGAAAAAMAkhG4AAAAAAExC6AYAAAAAwCSEbgAAAAAATELoBgAAAADAJIRuAAAAAABMQugGAAAAAMAkhG4AAAAAAExC6AYAAAAAwCSEbgAAAAAATELoBgAAAADAJIRuAAAAAABMQugGAAAAAMAkhG4AAAAAAExC6AYAAAAAwCSEbgAAAAAATELoBgAAAADAJIRuAAAAAABMQugGAAAAAMAkhG4AAAAAAExC6AYAAAAAwCRXHboLCwu1b98+XbhwoTzrAQAAAACg0rA7dJ89e1aDBw9WtWrV1KJFCx06dEiS9PTTT2vy5MnlXiAAAAAAABWV3aE7Pj5e3333ndatWyc3Nzdre0REhJYvX16uxQEAAAAAUJFVsfeAlJQULV++XHfddZcsFou1vUWLFjpw4EC5FgcAAAAAQEVm90r38ePH5ePjU6I9Pz/fJoQDAAAAAHCzszt0t2nTRqtXr7buXwza8+fPV7t27cqvMgAAAAAAKji7by+fNGmSoqKitGfPHl24cEEzZszQnj17tHHjRn355Zdm1AgAAAAAQIVk90p3x44d9d133+nChQsKDg7WZ599Jh8fH23atElhYWFm1AgAAAAAQIVkV+g+f/68Hn/8cVksFr311lvasmWL9uzZo/fee0/BwcF2n3z9+vXq0aOHAgICZLFYlJKSctnxH374oe6//37VqVNHnp6eateunT799FObMWPHjpXFYrHZmjVrZndtAAAAAABcK7tCd9WqVfXBBx+U28nz8/PVqlUrzZ49u0zj169fr/vvv19r1qzRtm3b1KVLF/Xo0UM7duywGdeiRQtlZmZat6+//rrcagYAAAAAoKzsfqa7Z8+eSklJ0bPPPnvNJ4+KilJUVFSZx0+fPt1mf9KkSVq1apX+/e9/q3Xr1tb2KlWqyM/P75rrAwAAAADgWtgdups0aaJx48Zpw4YNCgsLk4eHh03/M888U27FXUlxcbHOnDkjb29vm/b9+/crICBAbm5uateunZKSklSvXr1LzlNQUKCCggLrfm5urmk1AwAAAABuHnaH7gULFqhmzZratm2btm3bZtNnsViua+h+7bXXlJeXpz59+ljbwsPDlZycrKZNmyozM1OJiYnq1KmTdu3apRo1apQ6T1JSkhITE69X2QAAAACAm4TdoTsjI8OMOuy2ZMkSJSYmatWqVfLx8bG2//F29ZCQEIWHh6t+/fpasWKFBg8eXOpc8fHxio2Nte7n5uYqMDDQvOIBAAAAADcFu0P3HxmGIem3Fe7radmyZRoyZIhWrlypiIiIy46tWbOmbrvtNqWnp19yjKurq1xdXcu7TAAAAADATc7u73RL0qJFixQcHCx3d3e5u7srJCRE7777bnnXVqqlS5cqJiZGS5cuVffu3a84Pi8vTwcOHJC/v/91qA4AAAAAgN/ZvdI9bdo0jR49Wk899ZQ6dOggSfr666/1xBNP6MSJE3a91TwvL89mBTojI0M7d+6Ut7e36tWrp/j4eB09elSLFi2S9Nst5dHR0ZoxY4bCw8OVlZUlSXJ3d5eXl5ckaeTIkerRo4fq16+vX375RWPGjJGzs7P69+9v76UCAAAAAHBN7A7dr7/+uubOnauBAwda2x566CG1aNFCY8eOtSt0b926VV26dLHuX3yuOjo6WsnJycrMzNShQ4es/W+++aYuXLigJ598Uk8++aS1/eJ4STpy5Ij69++vkydPqk6dOurYsaO++eYb1alTx95LBQAAAADgmliMiw9ml5Gbm5t27dqlxo0b27Tv379fwcHBOnfuXLkW6Ai5ubny8vJSTk6OPD09HV3OJTWIW+3oEgAAAADAFAcnX/lxYkcqa260+5nuxo0ba8WKFSXaly9friZNmtg7HQAAAAAAlZbdt5cnJiaqb9++Wr9+vfWZ7g0bNigtLa3UMA4AAAAAwM3K7pXuv/zlL9q8ebNq166tlJQUpaSkqHbt2tqyZYseeeQRM2oEAAAAAKBCuqrvdIeFhem9994r71oAAAAAAKhU7F7pXrNmjT799NMS7Z9++qk++eSTcikKAAAAAIDKwO7QHRcXp6KiohLthmEoLi6uXIoCAAAAAKAysDt079+/X82bNy/R3qxZM6Wnp5dLUQAAAAAAVAZ2h24vLy/99NNPJdrT09Pl4eFRLkUBAAAAAFAZ2B26H374YY0YMUIHDhywtqWnp+u5557TQw89VK7FAQAAAABQkdkduqdMmSIPDw81a9ZMQUFBCgoK0u23365bbrlFr732mhk1AgAAAABQIdn9yTAvLy9t3LhRa9eu1XfffSd3d3eFhITo7rvvNqM+AAAAAAAqrKv6TrfFYlHXrl3VtWvX8q4HAAAAAIBKo8y3l2/atEkff/yxTduiRYsUFBQkHx8fDRs2TAUFBeVeIAAAAAAAFVWZQ/e4ceO0e/du6/4PP/ygwYMHKyIiQnFxcfr3v/+tpKQkU4oEAAAAAKAiKnPo3rlzp+677z7r/rJlyxQeHq633npLsbGxmjlzplasWGFKkQAAAAAAVERlDt2nTp2Sr6+vdf/LL79UVFSUdb9t27Y6fPhw+VYHAAAAAEAFVubQ7evrq4yMDElSYWGhtm/frrvuusvaf+bMGVWtWrX8KwQAAAAAoIIqc+h+4IEHFBcXp6+++krx8fGqVq2aOnXqZO3//vvv1ahRI1OKBAAAAACgIirzJ8PGjx+vXr16qXPnzqpevbreeecdubi4WPsXLlzIJ8QAAAAAAPiDMofu2rVra/369crJyVH16tXl7Oxs079y5UpVr1693AsEAAAAAKCiKnPovsjLy6vUdm9v72suBgAAAACAyqTMz3QDAAAAAAD7ELoBAAAAADAJoRsAAAAAAJMQugEAAAAAMMlVhe53331XHTp0UEBAgH7++WdJ0vTp07Vq1apyLQ4AAAAAgIrM7tA9d+5cxcbG6oEHHtDp06dVVFQkSapZs6amT59e3vUBAAAAAFBh2R26X3/9db311lt66aWXbL7V3aZNG/3www/lWhwAAAAAABWZ3aE7IyNDrVu3LtHu6uqq/Pz8cikKAAAAAIDKwO7QHRQUpJ07d5ZoT01N1e23314eNQEAAAAAUClUsfeA2NhYPfnkkzp37pwMw9CWLVu0dOlSJSUlaf78+WbUCAAAAABAhWR36B4yZIjc3d318ssv6+zZsxowYIACAgI0Y8YM9evXz4waAQAAAACokOwO3ZL02GOP6bHHHtPZs2eVl5cnHx+f8q4LAAAAAIAKz+7QnZGRoQsXLqhJkyaqVq2aqlWrJknav3+/qlatqgYNGpR3jQAAAAAAVEh2v0ht0KBB2rhxY4n2zZs3a9CgQeVREwAAAAAAlYLdoXvHjh3q0KFDifa77rqr1LeaAwAAAABws7I7dFssFp05c6ZEe05OjoqKisqlKAAAAAAAKgO7Q/fdd9+tpKQkm4BdVFSkpKQkdezYsVyLAwAAAACgIrP7RWqvvPKK7r77bjVt2lSdOnWSJH311VfKzc3V559/Xu4FAgAAAABQUdm90t28eXN9//336tOnj44dO6YzZ85o4MCB2rt3r1q2bGlGjQAAAAAAVEhX9Z3ugIAATZo0qbxrAQAAAACgUrmq0H369Glt2bJFx44dU3FxsU3fwIEDy6UwAAAAAAAqOrtD97///W899thjysvLk6enpywWi7XPYrEQugEAAAAA+B+7n+l+7rnn9PjjjysvL0+nT5/WqVOnrNuvv/5qRo0AAAAAAFRIdofuo0eP6plnnlG1atXMqAcAAAAAgErD7tAdGRmprVu3mlELAAAAAACVit3PdHfv3l3PP/+89uzZo+DgYFWtWtWm/6GHHiq34gAAAAAAqMjsDt1Dhw6VJI0bN65En8ViUVFR0bVXBQAAAABAJWB36P7zJ8IAAAAAAEDp7H6muzytX79ePXr0UEBAgCwWi1JSUq54zLp163THHXfI1dVVjRs3VnJycokxs2fPVoMGDeTm5qbw8HBt2bKl/IsHAAAAAOAK7F7plqT8/Hx9+eWXOnTokAoLC236nnnmGbvmadWqlR5//HH16tXriuMzMjLUvXt3PfHEE1q8eLHS0tI0ZMgQ+fv7KzIyUpK0fPlyxcbGat68eQoPD9f06dMVGRmpffv2ycfHx74LBQAAAADgGlgMwzDsOWDHjh164IEHdPbsWeXn58vb21snTpxQtWrV5OPjo59++unqCrFY9NFHH6lnz56XHPPiiy9q9erV2rVrl7WtX79+On36tFJTUyVJ4eHhatu2rWbNmiXpt9vhAwMD9fTTTysuLq5MteTm5srLy0s5OTny9PS8quu5HhrErXZ0CQAAAABgioOTuzu6hMsqa260+/byZ599Vj169NCpU6fk7u6ub775Rj///LPCwsL02muvXVPRV7Jp0yZFRETYtEVGRmrTpk2SpMLCQm3bts1mjJOTkyIiIqxjAAAAAAC4XuwO3Tt37tRzzz0nJycnOTs7q6CgQIGBgZoyZYpGjRplRo1WWVlZ8vX1tWnz9fVVbm6u/u///k8nTpxQUVFRqWOysrIuOW9BQYFyc3NtNgAAAAAArpXdobtq1apycvrtMB8fHx06dEiS5OXlpcOHD5dvdddJUlKSvLy8rFtgYKCjSwIAAAAAVAJ2h+7WrVvr22+/lSR17txZCQkJWrx4sUaMGKGWLVuWe4F/5Ofnp+zsbJu27OxseXp6yt3dXbVr15azs3OpY/z8/C45b3x8vHJycqxbRf3HAwAAAADAjcXu0D1p0iT5+/tLkiZOnKhatWpp+PDhOn78uN54441yL/CP2rVrp7S0NJu2tWvXql27dpIkFxcXhYWF2YwpLi5WWlqadUxpXF1d5enpabMBAAAAAHCt7P5kWJs2bax/9vHxsb41/Grk5eUpPT3dup+RkaGdO3fK29tb9erVU3x8vI4ePapFixZJkp544gnNmjVLL7zwgh5//HF9/vnnWrFihVav/v0t3rGxsYqOjlabNm105513avr06crPz1dMTMxV1wkAAAAAwNWwe6X73nvv1enTp0u05+bm6t5777Vrrq1bt6p169Zq3bq1pN8Cc+vWrZWQkCBJyszMtD4zLklBQUFavXq11q5dq1atWmnq1KmaP3++9RvdktS3b1+99tprSkhIUGhoqHbu3KnU1NQSL1cDAAAAAMBsdn+n28nJSVlZWfLx8bFpP3bsmOrWravz58+Xa4GOwHe6AQAAAMCxKst3ust8e/n3339v/fOePXtsPsFVVFSk1NRU1a1b9yrLBQAAAACg8ilz6A4NDZXFYpHFYin1NnJ3d3e9/vrr5VocAAAAAAAVWZlDd0ZGhgzDUMOGDbVlyxbVqVPH2ufi4iIfHx85OzubUiQAAAAAABVRmUN3/fr1df78eUVHR+uWW25R/fr1zawLAAAAAIAKz663l1etWlUfffSRWbUAAAAAAFCp2P3JsIcfflgpKSkmlAIAAAAAQOVS5tvLL2rSpInGjRunDRs2KCwsTB4eHjb9zzzzTLkVBwAAAABARWZ36F6wYIFq1qypbdu2adu2bTZ9FouF0A0AAAAAwP/YHbozMjLMqAMAAAAAgErH7me6/8gwDBmGUV61AAAAAABQqVxV6F60aJGCg4Pl7u4ud3d3hYSE6N133y3v2gAAAAAAqNDsvr182rRpGj16tJ566il16NBBkvT111/riSee0IkTJ/Tss8+We5EAAAAAAFREdofu119/XXPnztXAgQOtbQ899JBatGihsWPHEroBAAAAAPgfu28vz8zMVPv27Uu0t2/fXpmZmeVSFAAAAAAAlYHdobtx48ZasWJFifbly5erSZMm5VIUAAAAAACVgd23lycmJqpv375av3699ZnuDRs2KC0trdQwDgAAAADAzcrule6//OUv2rx5s2rXrq2UlBSlpKSodu3a2rJlix555BEzagQAAAAAoEKye6VbksLCwvTee++Vdy0AAAAAAFQqVxW6i4qK9NFHH+nHH3+UJDVv3lwPP/ywqlS5qukAAAAAAKiU7E7Ju3fv1kMPPaSsrCw1bdpUkvTKK6+oTp06+ve//62WLVuWe5EAAAAAAFREdj/TPWTIELVo0UJHjhzR9u3btX37dh0+fFghISEaNmyYGTUCAAAAAFAh2b3SvXPnTm3dulW1atWyttWqVUsTJ05U27Zty7U4AAAAAAAqMrtXum+77TZlZ2eXaD927JgaN25cLkUBAAAAAFAZ2B26k5KS9Mwzz+j999/XkSNHdOTIEb3//vsaMWKEXnnlFeXm5lo3AAAAAABuZnbfXv7ggw9Kkvr06SOLxSJJMgxDktSjRw/rvsViUVFRUXnVCQAAAABAhWN36P7iiy/MqAMAAAAAgErH7tDduXNnM+oAAAAAAKDSsTt0S9K5c+f0/fff69ixYyouLrbpe+ihh8qlMAAAAAAAKjq7Q3dqaqoGDhyoEydOlOjjOW4AAAAAAH5n99vLn376afXu3VuZmZkqLi622QjcAAAAAAD8zu7QnZ2drdjYWPn6+ppRDwAAAAAAlYbdofvRRx/VunXrTCgFAAAAAIDKxe5numfNmqXevXvrq6++UnBwsKpWrWrT/8wzz5RbcQAAAAAAVGR2h+6lS5fqs88+k5ubm9atWyeLxWLts1gshG4AAAAAAP7H7tD90ksvKTExUXFxcXJysvvudAAAAAAAbhp2p+bCwkL17duXwA0AAAAAwBXYnZyjo6O1fPlyM2oBAAAAAKBSsfv28qKiIk2ZMkWffvqpQkJCSrxIbdq0aeVWHAAAAAAAFZndofuHH35Q69atJUm7du2y6fvjS9UAAAAAALjZ2R26v/jiCzPqAAAAAACg0uFtaAAAAAAAmKTMK929evUq07gPP/zwqosBAAAAAKAyKXPo9vLyMrMOAAAAAAAqnTKH7rffftvMOgAAAAAAqHR4phsAAAAAAJMQugEAAAAAMAmhGwAAAAAAkxC6AQAAAAAwCaEbAAAAAACT3BChe/bs2WrQoIHc3NwUHh6uLVu2XHLsPffcI4vFUmLr3r27dcygQYNK9Hfr1u16XAoAAAAAAFZl/mSYWZYvX67Y2FjNmzdP4eHhmj59uiIjI7Vv3z75+PiUGP/hhx+qsLDQun/y5Em1atVKvXv3thnXrVs3m8+cubq6mncRAAAAAACUwuEr3dOmTdPQoUMVExOj5s2ba968eapWrZoWLlxY6nhvb2/5+flZt7Vr16patWolQrerq6vNuFq1al2PywEAAAAAwMqhobuwsFDbtm1TRESEtc3JyUkRERHatGlTmeZYsGCB+vXrJw8PD5v2devWycfHR02bNtXw4cN18uTJcq0dAAAAAIArcejt5SdOnFBRUZF8fX1t2n19fbV3794rHr9lyxbt2rVLCxYssGnv1q2bevXqpaCgIB04cECjRo1SVFSUNm3aJGdn5xLzFBQUqKCgwLqfm5t7lVcEAAAAAMDvHP5M97VYsGCBgoODdeedd9q09+vXz/rn4OBghYSEqFGjRlq3bp3uu+++EvMkJSUpMTHR9HoBAAAAADcXh95eXrt2bTk7Oys7O9umPTs7W35+fpc9Nj8/X8uWLdPgwYOveJ6GDRuqdu3aSk9PL7U/Pj5eOTk51u3w4cNlvwgAAAAAAC7BoaHbxcVFYWFhSktLs7YVFxcrLS1N7dq1u+yxK1euVEFBgf76179e8TxHjhzRyZMn5e/vX2q/q6urPD09bTYAAAAAAK6Vw99eHhsbq7feekvvvPOOfvzxRw0fPlz5+fmKiYmRJA0cOFDx8fEljluwYIF69uypW265xaY9Ly9Pzz//vL755hsdPHhQaWlpevjhh9W4cWNFRkZel2sCAAAAAEC6AZ7p7tu3r44fP66EhARlZWUpNDRUqamp1perHTp0SE5Otv82sG/fPn399df67LPPSszn7Oys77//Xu+8845Onz6tgIAAde3aVePHj+db3QAAAACA68piGIbh6CJuNLm5ufLy8lJOTs4Nfat5g7jVji4BAAAAAExxcHJ3R5dwWWXNjQ6/vRwAAAAAgMqK0A0AAAAAgEkI3QAAAAAAmITQDQAAAACASQjdAAAAAACYhNANAAAAAIBJCN0AAAAAAJiE0A0AAAAAgEkI3QAAAAAAmITQDQAAAACASQjdAAAAAACYhNANAAAAAIBJCN0AAAAAAJiE0A0AAAAAgEkI3QAAAAAAmITQDQAAAACASQjdAAAAAACYhNANAAAAAIBJCN0AAAAAAJiE0A0AAAAAgEkI3QAAAAAAmITQDQAAAACASQjdAAAAAACYhNANAAAAAIBJCN0AAAAAAJiE0A0AAAAAgEkI3QAAAAAAmITQDQAAAACASQjdAAAAAACYhNANAAAAAIBJCN0AAAAAAJiE0A0AAAAAgEkI3QAAAAAAmITQDQAAAACASQjdAAAAAACYhNANAAAAAIBJCN0AAAAAAJiE0A0AAAAAgEkI3QAAAAAAmITQDQAAAACASQjdAAAAAACYhNANAAAAAIBJCN0AAAAAAJiE0A0AAAAAgEkI3QAAAAAAmITQDQAAAACASQjdAAAAAACYhNANAAAAAIBJCN0AAAAAAJjkhgjds2fPVoMGDeTm5qbw8HBt2bLlkmOTk5NlsVhsNjc3N5sxhmEoISFB/v7+cnd3V0REhPbv32/2ZQAAAAAAYMPhoXv58uWKjY3VmDFjtH37drVq1UqRkZE6duzYJY/x9PRUZmamdfv5559t+qdMmaKZM2dq3rx52rx5szw8PBQZGalz586ZfTkAAAAAAFg5PHRPmzZNQ4cOVUxMjJo3b6558+apWrVqWrhw4SWPsVgs8vPzs26+vr7WPsMwNH36dL388st6+OGHFRISokWLFumXX35RSkrKdbgiAAAAAAB+49DQXVhYqG3btikiIsLa5uTkpIiICG3atOmSx+Xl5al+/foKDAzUww8/rN27d1v7MjIylJWVZTOnl5eXwsPDLzsnAAAAAADlzaGh+8SJEyoqKrJZqZYkX19fZWVllXpM06ZNtXDhQq1atUrvvfeeiouL1b59ex05ckSSrMfZM2dBQYFyc3NtNgAAAAAArpXDby+3V7t27TRw4ECFhoaqc+fO+vDDD1WnTh298cYbVz1nUlKSvLy8rFtgYGA5VgwAAAAAuFk5NHTXrl1bzs7Oys7OtmnPzs6Wn59fmeaoWrWqWrdurfT0dEmyHmfPnPHx8crJybFuhw8ftvdSAAAAAAAowaGh28XFRWFhYUpLS7O2FRcXKy0tTe3atSvTHEVFRfrhhx/k7+8vSQoKCpKfn5/NnLm5udq8efMl53R1dZWnp6fNBgAAAADAtari6AJiY2MVHR2tNm3a6M4779T06dOVn5+vmJgYSdLAgQNVt25dJSUlSZLGjRunu+66S40bN9bp06f16quv6ueff9aQIUMk/fZm8xEjRmjChAlq0qSJgoKCNHr0aAUEBKhnz56OukwAAAAAwE3I4aG7b9++On78uBISEpSVlaXQ0FClpqZaX4R26NAhOTn9viB/6tQpDR06VFlZWapVq5bCwsK0ceNGNW/e3DrmhRdeUH5+voYNG6bTp0+rY8eOSk1NlZub23W/PgAAAADAzctiGIbh6CJuNLm5ufLy8lJOTs4Nfat5g7jVji4BAAAAAExxcHJ3R5dwWWXNjRXu7eUAAAAAAFQUhG4AAAAAAExC6AYAAAAAwCSEbgAAAAAATELoBgAAAADAJIRuAAAAAABMQugGAAAAAMAkhG4AAAAAAExC6AYAAAAAwCSEbgAAAAAATELoBgAAAADAJIRuAAAAAABMQugGAAAAAMAkhG4AAAAAAExC6AYAAAAAwCSEbgAAAAAATELoBgAAAADAJIRuAAAAAABMQugGAAAAAMAkhG4AAAAAAExC6AYAAAAAwCSEbgAAAAAATELoBgAAAADAJIRuAAAAAABMQugGAAAAAMAkhG4AAAAAAExC6AYAAAAAwCSEbgAAAAAATELoBgAAAADAJIRuAAAAAABMQugGAAAAAMAkhG4AAAAAAExC6AYAAAAAwCSEbgAAAAAATELoBgAAAADAJIRuAAAAAABMQugGAAAAAMAkhG4AAAAAAExC6AYAAAAAwCSEbgAAAAAATELoBgAAAADAJIRuAAAAAABMQugGAAAAAMAkhG4AAAAAAExC6AYAAAAAwCSEbgAAAAAATELoBgAAAADAJIRuAAAAAABMQugGAAAAAMAkN0Tonj17tho0aCA3NzeFh4dry5Ytlxz71ltvqVOnTqpVq5Zq1aqliIiIEuMHDRoki8Vis3Xr1s3sywAAAAAAwIbDQ/fy5csVGxurMWPGaPv27WrVqpUiIyN17NixUsevW7dO/fv31xdffKFNmzYpMDBQXbt21dGjR23GdevWTZmZmdZt6dKl1+NyAAAAAACwcnjonjZtmoYOHaqYmBg1b95c8+bNU7Vq1bRw4cJSxy9evFh///vfFRoaqmbNmmn+/PkqLi5WWlqazThXV1f5+flZt1q1al2PywEAAAAAwMqhobuwsFDbtm1TRESEtc3JyUkRERHatGlTmeY4e/aszp8/L29vb5v2devWycfHR02bNtXw4cN18uTJcq0dAAAAAIArqeLIk584cUJFRUXy9fW1aff19dXevXvLNMeLL76ogIAAm+DerVs39erVS0FBQTpw4IBGjRqlqKgobdq0Sc7OziXmKCgoUEFBgXU/Nzf3Kq8IAAAAAIDfOTR0X6vJkydr2bJlWrdundzc3Kzt/fr1s/45ODhYISEhatSokdatW6f77ruvxDxJSUlKTEy8LjUDAAAAAG4eDr29vHbt2nJ2dlZ2drZNe3Z2tvz8/C577GuvvabJkyfrs88+U0hIyGXHNmzYULVr11Z6enqp/fHx8crJybFuhw8ftu9CAAAAAAAohUNDt4uLi8LCwmxegnbxpWjt2rW75HFTpkzR+PHjlZqaqjZt2lzxPEeOHNHJkyfl7+9far+rq6s8PT1tNgAAAAAArpXD314eGxurt956S++8845+/PFHDR8+XPn5+YqJiZEkDRw4UPHx8dbxr7zyikaPHq2FCxeqQYMGysrKUlZWlvLy8iRJeXl5ev755/XNN9/o4MGDSktL08MPP6zGjRsrMjLSIdcIAAAAALg5OfyZ7r59++r48eNKSEhQVlaWQkNDlZqaan252qFDh+Tk9Pu/DcydO1eFhYV69NFHbeYZM2aMxo4dK2dnZ33//fd65513dPr0aQUEBKhr164aP368XF1dr+u1AQAAAABubhbDMAxHF3Gjyc3NlZeXl3Jycm7oW80bxK12dAkAAAAAYIqDk7s7uoTLKmtudPjt5QAAAAAAVFaEbgAAAAAATELoBgAAAADAJIRuAAAAAABMQugGAAAAAMAkhG4AAAAAAExC6AYAAAAAwCSEbgAAAAAATELoBgAAAADAJIRuAAAAAABMQugGAAAAAMAkhG4AAAAAAExC6AYAAAAAwCSEbgAAAAAATELoBgAAAADAJIRuAAAAAABMQugGAAAAAMAkhG4AAAAAAExC6AYAAAAAwCSEbgAAAAAATELoBgAAAADAJIRuAAAAAABMQugGAAAAAMAkhG4AAAAAAExC6AYAAAAAwCSEbgAAAAAATELoBgAAAADAJIRuAAAAAABMQugGAAAAAMAkhG4AAAAAAExC6AYAAAAAwCSEbgAAAAAATELoBgAAAADAJIRuAAAAAABMQugGAAAAAMAkhG4AAAAAAExC6AYAAAAAwCSEbgAAAAAATELoBgAAAADAJIRuAAAAAABMQugGAAAAAMAkhG4AAAAAAExC6AYAAAAAwCSEbgAAAAAATELoBgAAAADAJIRuAAAAAABMQugGAAAAAMAkhG4AAAAAAExC6AYAAAAAwCQ3ROiePXu2GjRoIDc3N4WHh2vLli2XHb9y5Uo1a9ZMbm5uCg4O1po1a2z6DcNQQkKC/P395e7uroiICO3fv9/MSwAAAAAAoASHh+7ly5crNjZWY8aM0fbt29WqVStFRkbq2LFjpY7fuHGj+vfvr8GDB2vHjh3q2bOnevbsqV27dlnHTJkyRTNnztS8efO0efNmeXh4KDIyUufOnbtelwUAAAAAgCyGYRiOLCA8PFxt27bVrFmzJEnFxcUKDAzU008/rbi4uBLj+/btq/z8fH388cfWtrvuukuhoaGaN2+eDMNQQECAnnvuOY0cOVKSlJOTI19fXyUnJ6tfv35XrCk3N1deXl7KycmRp6dnOV1p+WsQt9rRJQAAAACAKQ5O7u7oEi6rrLnRoSvdhYWF2rZtmyIiIqxtTk5OioiI0KZNm0o9ZtOmTTbjJSkyMtI6PiMjQ1lZWTZjvLy8FB4efsk5AQAAAAAwQxVHnvzEiRMqKiqSr6+vTbuvr6/27t1b6jFZWVmljs/KyrL2X2y71Jg/KygoUEFBgXU/JydH0m//cnEjKy446+gSAAAAAMAUN3oeu1jflW4ed2jovlEkJSUpMTGxRHtgYKADqgEAAAAAeE13dAVlc+bMGXl5eV2y36Ghu3bt2nJ2dlZ2drZNe3Z2tvz8/Eo9xs/P77LjL/5ndna2/P39bcaEhoaWOmd8fLxiY2Ot+8XFxfr11191yy23yGKx2H1dAABUNrm5uQoMDNThw4dv6PedAABwvRiGoTNnziggIOCy4xwaul1cXBQWFqa0tDT17NlT0m+BNy0tTU899VSpx7Rr105paWkaMWKEtW3t2rVq166dJCkoKEh+fn5KS0uzhuzc3Fxt3rxZw4cPL3VOV1dXubq62rTVrFnzmq4NAIDKyNPTk9ANAMD/XG6F+yKH314eGxur6OhotWnTRnfeeaemT5+u/Px8xcTESJIGDhyounXrKikpSZL0j3/8Q507d9bUqVPVvXt3LVu2TFu3btWbb74pSbJYLBoxYoQmTJigJk2aKCgoSKNHj1ZAQIA12AMAAAAAcD04PHT37dtXx48fV0JCgrKyshQaGqrU1FTri9AOHTokJ6ffX7Levn17LVmyRC+//LJGjRqlJk2aKCUlRS1btrSOeeGFF5Sfn69hw4bp9OnT6tixo1JTU+Xm5nbdrw8AAAAAcPNy+He6AQDAja+goEBJSUmKj48v8UgWAAC4NEI3AAAAAAAmcbryEAAAAAAAcDUI3QAAAAAAmITQDQAAAACASQjdAABUcM8884zCwsLk6uqq0NDQy45NT09XjRo1VLNmzRJ906dPV9OmTeXu7q7AwEA9++yzOnfunLV//fr16tGjhwICAmSxWJSSklJiDovFUur26quvWsds375d999/v2rWrKlbbrlFw4YNU15ens08aWlpat++vWrUqCE/Pz+9+OKLunDhgrV/7NixpZ7Hw8OjbD8aAADXCaEbAIBK4PHHH1ffvn0vO+b8+fPq37+/OnXqVKJvyZIliouL05gxY/Tjjz9qwYIFWr58uUaNGmUdk5+fr1atWmn27NmXPEdmZqbNtnDhQlksFv3lL3+RJP3yyy+KiIhQ48aNtXnzZqWmpmr37t0aNGiQdY7vvvtODzzwgLp166YdO3Zo+fLl+te//qW4uDjrmJEjR5Y4V/PmzdW7d++y/mQAAFwXhG4AABysuLhYU6ZMUePGjeXq6qp69epp4sSJkqSNGzcqNDRUbm5uatOmjVJSUmSxWLRz507r8TNnztSTTz6phg0bXvY8L7/8spo1a6Y+ffqU6Nu4caM6dOigAQMGqEGDBuratav69++vLVu2WMdERUVpwoQJeuSRRy55Dj8/P5tt1apV6tKli7W2jz/+WFWrVtXs2bPVtGlTtW3bVvPmzdMHH3yg9PR0SdLy5csVEhKihIQENW7cWJ07d9aUKVM0e/ZsnTlzRpJUvXp1m/NkZ2drz549Gjx4cNl+dAAArhNCNwAADhYfH6/Jkydr9OjR2rNnj5YsWSJfX1/l5uaqR48eCg4O1vbt2zV+/Hi9+OKLV3WOzz//XCtXrrzkKnX79u21bds2a8j+6aeftGbNGj3wwANXfV3Z2dlavXq1TRAuKCiQi4uLnJx+/78g7u7ukqSvv/7aOsbNzc1mLnd3d507d07btm0r9Vzz58/XbbfdVuoqPgAAjkToBgDAgc6cOaMZM2ZoypQpio6OVqNGjdSxY0cNGTJES5YskcVi0VtvvaXmzZsrKipKzz//vN3nOHnypAYNGqTk5GR5enqWOmbAgAEaN26cOnbsqKpVq6pRo0a65557bG4vt9c777yjGjVqqFevXta2e++9V1lZWXr11VdVWFioU6dOWW8bz8zMlCRFRkZq48aNWrp0qYqKinT06FGNGzfOZswfnTt3TosXL2aVGwBwQyJ0AwDgQD/++KMKCgp03333lejbt2+fQkJCbFZ977zzTrvPMXToUA0YMEB33333JcesW7dOkyZN0pw5c7R9+3Z9+OGHWr16tcaPH2/3+S5auHChHnvsMZv6W7RooXfeeUdTp05VtWrV5Ofnp6CgIPn6+lpXv7t27apXX31VTzzxhFxdXXXbbbdZV9z/uEJ+0UcffaQzZ84oOjr6qmsFAMAshG4AABzo4q3VZvr888/12muvqUqVKqpSpYoGDx6snJwcValSRQsXLpQkjR49Wn/72980ZMgQBQcH65FHHtGkSZOUlJSk4uJiu8/51Vdfad++fRoyZEiJvgEDBigrK0tHjx7VyZMnNXbsWB0/ftzmmfTY2FidPn1ahw4d0okTJ/Twww9LUqnPrc+fP18PPvigfH197a4TAACzVXF0AQAA3MyaNGkid3d3paWllQioTZs21XvvvaeCggK5urpKkr799lu7z7Fp0yYVFRVZ91etWqVXXnlFGzduVN26dSVJZ8+eLbGK7OzsLEkyDMPucy5YsEBhYWFq1arVJcdcDMkLFy6Um5ub7r//fpt+i8WigIAASdLSpUsVGBioO+64w2ZMRkaGvvjiC/3rX/+yu0YAAK4HQjcAAA7k5uamF198US+88IJcXFzUoUMHHT9+XLt379aAAQP00ksvadiwYYqLi9OhQ4f02muvSfotkF6Unp6uvLw8ZWVl6f/+7/+sbzZv3ry5XFxcdPvtt9ucc+vWrXJyclLLli2tbT169NC0adPUunVrhYeHKz09XaNHj1aPHj2s4TsvL8/6hnHpt8C7c+dOeXt7q169etb23NxcrVy5UlOnTi31mmfNmqX27durevXqWrt2rZ5//nlNnjzZ5tvhr776qrp16yYnJyd9+OGHmjx5slasWGGt5aKFCxfK399fUVFRdvzqAABcRwYAAHCooqIiY8KECUb9+vWNqlWrGvXq1TMmTZpkGIZhbNiwwQgJCTFcXFyMsLAwY8mSJYYkY+/evdbjO3fubEgqsWVkZJR6vrffftvw8vKyaTt//rwxduxYo1GjRoabm5sRGBho/P3vfzdOnTplHfPFF1+Uep7o6Gibud544w3D3d3dOH36dKnn/9vf/mZ4e3sbLi4uRkhIiLFo0aISY7p06WJ4eXkZbm5uRnh4uLFmzZpSf7dbb73VGDVqVKnnAQDgRmAxjKu4ZwwAADjE4sWLFRMTo5ycnOvyPDgAALg23F4OAMANbNGiRWrYsKHq1q2r7777Ti+++KL69OlD4AYAoIIgdAMAcAPLyspSQkKCsrKy5O/vr969e2vixImOLgsAAJQRt5cDAAAAAGASvtMNAAAAAIBJCN0AAAAAAJiE0A0AAAAAgEkI3QAAAAAAmITQDQAAAACASQjdAAAAAACYhNANAEAFNWjQIFkslhJbenr6Nc+dnJysmjVrXnuRAADc5Ko4ugAAAHD1unXrprffftumrU6dOg6qpnTnz59X1apVHV0GAAAOwUo3AAAVmKurq/z8/Gw2Z2dnrVq1SnfccYfc3NzUsGFDJSYm6sKFC9bjpk2bpuDgYHl4eCgwMFB///vflZeXJ0lat26dYmJilJOTY109Hzt2rCTJYrEoJSXFpoaaNWsqOTlZknTw4EFZLBYtX75cnTt3lpubmxYvXixJmj9/vm6//Xa5ubmpWbNmmjNnjnWOwsJCPfXUU/L395ebm5vq16+vpKQk8344AACuE1a6AQCoZL766isNHDhQM2fOVKdOnXTgwAENGzZMkjRmzBhJkpOTk2bOnKmgoCD99NNP+vvf/64XXnhBc+bMUfv27TV9+nQlJCRo3759kqTq1avbVUNcXJymTp2q1q1bW4N3QkKCZs2apdatW2vHjh0aOnSoPDw8FB0drZkzZ+pf//qXVqxYoXr16unw4cM6fPhw+f4wAAA4AKEbAIAK7OOPP7YJxFFRUTp16pTi4uIUHR0tSWrYsKHGjx+vF154wRq6R4wYYT2mQYMGmjBhgp544gnNmTNHLi4u8vLyksVikZ+f31XVNWLECPXq1cu6P2bMGE2dOtXaFhQUpD179uiNN95QdHS0Dh06pCZNmqhjx46yWCyqX7/+VZ0XAIAbDaEbAIAKrEuXLpo7d65138PDQyEhIdqwYYMmTpxobS8qKtK5c+d09uxZVatWTf/5z3+UlJSkvXv3Kjc3VxcuXLDpv1Zt2rSx/jk/P18HDhzQ4MGDNXToUGv7hQsX5OXlJem3l8Ldf//9atq0qbp166YHH3xQXbt2veY6AABwNEI3AAAVmIeHhxo3bmzTlpeXp8TERJuV5ovc3Nx08OBBPfjggxo+fLgmTpwob29vff311xo8eLAKCwsvG7otFosMw7BpO3/+fKl1/bEeSXrrrbcUHh5uM87Z2VmSdMcddygjI0OffPKJ/vOf/6hPnz6KiIjQ+++/f4VfAACAGxuhGwCASuaOO+7Qvn37SoTxi7Zt26bi4mJNnTpVTk6/vVN1xYoVNmNcXFxUVFRU4tg6deooMzPTur9//36dPXv2svX4+voqICBAP/30kx577LFLjvP09FTfvn3Vt29fPfroo+rWrZt+/fVXeXt7X3Z+AABuZIRuAAAqmYSEBD344IOqV6+eHn30UTk5Oem7777Trl27NGHCBDVu3Fjnz5/X66+/rh49emjDhg2aN2+ezRwNGjRQXl6e0tLS1KpVK1WrVk3VqlXTvffeq1mzZqldu3YqKirSiy++WKbPgSUmJuqZZ56Rl5eXunXrpoKCAm3dulWnTp1SbGyspk2bJn9/f7Vu3VpOTk5auXKl/Pz8+FY4AKDC45NhAABUMpGRkfr444/12WefqW3btrrrrrv0z3/+0/pyslatWmnatGl65ZVX1LJlSy1evLjE57nat2+vJ554Qn379lWdOnU0ZcoUSdLUqVMVGBioTp06acCAARo5cmSZngEfMmSI5s+fr7ffflvBwcHq3LmzkpOTFRQUJEmqUaOGpkyZojZt2qht27Y6ePCg1qxZY12JBwCgorIYf34wCwAAAAAAlAv++RgAAAAAAJMQugEAAAAAMAmhGwAAAAAAkxC6AQAAAAAwCaEbAAAAAACTELoBAAAAADAJoRsAAAAAAJMQugEAAAAAMAmhGwAAAAAAkxC6AQAAAAAwCaEbAAAAAACTELoBAAAAADDJ/wc2QvTN6eckDQAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get feature importance\n",
    "importance = model.get_score(importance_type='weight')\n",
    "importance = sorted(importance.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# Print the top 10 most important features\n",
    "print(\"\\nTop 10 Most Important Features:\")\n",
    "for feature, score in importance[:10]:\n",
    "    print(f\"{feature}: {score}\")\n",
    "\n",
    "# If you want to visualize the feature importance\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot feature importance\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(range(len(importance)), [score for feature, score in importance])\n",
    "plt.xticks(range(len(importance)), [feature for feature, score in importance], rotation='horizontal')\n",
    "plt.title('Feature Importance')\n",
    "plt.xlabel('Features')\n",
    "plt.ylabel('Importance Score')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'cg14817997': 2.0}\n",
      "{'cg14817997': 359.0078125}\n",
      "{'cg14817997': 66.10433197021484}\n"
     ]
    }
   ],
   "source": [
    "print(model.get_score(importance_type='weight'))  # Feature counts\n",
    "print(model.get_score(importance_type='gain'))    # Feature gains\n",
    "print(model.get_score(importance_type='cover'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.2500\n",
      "Kappa: 0.0000\n",
      "Sensitivity: 0.2500\n",
      "Specificity: 0.7500\n",
      "Positive Predictive Value: 0.0625\n",
      "Negative Predictive Value: 0.5625\n",
      "Precision: 0.0625\n",
      "Recall: 0.2500\n",
      "F1 Score: 0.1000\n",
      "Balanced Accuracy: 0.5000\n",
      "AUC: 0.5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\arian\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, cohen_kappa_score, confusion_matrix, precision_score, recall_score, f1_score, roc_auc_score\n",
    "from sklearn.preprocessing import label_binarize\n",
    "import numpy as np\n",
    "\n",
    "# Predict labels and probabilities\n",
    "y_pred = model.predict(dtest)\n",
    "y_prob = model.predict(dtest, output_margin=True)\n",
    "\n",
    "# Calculate metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "kappa = cohen_kappa_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='weighted')\n",
    "recall = recall_score(y_test, y_pred, average='weighted')\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "# Confusion matrix and derived metrics\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "n_classes = len(np.unique(y_test))\n",
    "\n",
    "sensitivity = []\n",
    "specificity = []\n",
    "ppv = []\n",
    "npv = []\n",
    "\n",
    "for i in range(n_classes):\n",
    "    tp = cm[i, i]\n",
    "    fn = np.sum(cm[i, :]) - tp\n",
    "    fp = np.sum(cm[:, i]) - tp\n",
    "    tn = np.sum(cm) - (tp + fn + fp)\n",
    "    \n",
    "    sensitivity.append(tp / (tp + fn) if (tp + fn) > 0 else 0)\n",
    "    specificity.append(tn / (tn + fp) if (tn + fp) > 0 else 0)\n",
    "    ppv.append(tp / (tp + fp) if (tp + fp) > 0 else 0)\n",
    "    npv.append(tn / (tn + fn) if (tn + fn) > 0 else 0)\n",
    "\n",
    "balanced_accuracy = (np.mean(sensitivity) + np.mean(specificity)) / 2\n",
    "\n",
    "# AUC calculation\n",
    "y_test_bin = label_binarize(y_test, classes=range(n_classes))\n",
    "auc = roc_auc_score(y_test_bin, y_prob, average='weighted', multi_class='ovr')\n",
    "\n",
    "# Print results\n",
    "metrics = {\n",
    "    'Accuracy': accuracy,\n",
    "    'Kappa': kappa,\n",
    "    'Sensitivity': np.mean(sensitivity),\n",
    "    'Specificity': np.mean(specificity),\n",
    "    'Positive Predictive Value': np.mean(ppv),\n",
    "    'Negative Predictive Value': np.mean(npv),\n",
    "    'Precision': precision,\n",
    "    'Recall': recall,\n",
    "    'F1 Score': f1,\n",
    "    'Balanced Accuracy': balanced_accuracy,\n",
    "    'AUC': auc\n",
    "}\n",
    "\n",
    "for metric, value in metrics.items():\n",
    "    print(f\"{metric}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_model(\"xgboost4classModel.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set Performance:\n",
      "Accuracy: 0.3029\n",
      "Precision: 0.0917\n",
      "Recall: 0.3029\n",
      "F1 Score: 0.1408\n",
      "AUC: 0.5000\n",
      "\n",
      "Test Set Performance:\n",
      "Accuracy: 0.2500\n",
      "Precision: 0.0625\n",
      "Recall: 0.2500\n",
      "F1 Score: 0.1000\n",
      "AUC: 0.5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\arian\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\arian\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "def calculate_metrics(y_true, y_pred, y_prob):\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred, average='weighted')\n",
    "    recall = recall_score(y_true, y_pred, average='weighted')\n",
    "    f1 = f1_score(y_true, y_pred, average='weighted')\n",
    "    \n",
    "    # For multiclass AUC\n",
    "    n_classes = len(np.unique(y_true))\n",
    "    y_true_bin = label_binarize(y_true, classes=range(n_classes))\n",
    "    auc = roc_auc_score(y_true_bin, y_prob, average='weighted', multi_class='ovr')\n",
    "    \n",
    "    return {\n",
    "        'Accuracy': accuracy,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'F1 Score': f1,\n",
    "        'AUC': auc\n",
    "    }\n",
    "\n",
    "# Create DMatrix for training data if not already done\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "\n",
    "# Make predictions on training set\n",
    "y_train_pred = model.predict(dtrain)\n",
    "y_train_prob = model.predict(dtrain, output_margin=True)\n",
    "\n",
    "# Make predictions on test set\n",
    "y_test_pred = model.predict(dtest)\n",
    "y_test_prob = model.predict(dtest, output_margin=True)\n",
    "\n",
    "# Calculate metrics for training set\n",
    "train_metrics = calculate_metrics(y_train, y_train_pred, y_train_prob)\n",
    "\n",
    "# Calculate metrics for test set\n",
    "test_metrics = calculate_metrics(y_test, y_test_pred, y_test_prob)\n",
    "\n",
    "# Print results\n",
    "print(\"Training Set Performance:\")\n",
    "for metric, value in train_metrics.items():\n",
    "    print(f\"{metric}: {value:.4f}\")\n",
    "\n",
    "print(\"\\nTest Set Performance:\")\n",
    "for metric, value in test_metrics.items():\n",
    "    print(f\"{metric}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 3888 candidates, totalling 19440 fits\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 36\u001b[0m\n\u001b[0;32m     26\u001b[0m grid_search \u001b[38;5;241m=\u001b[39m GridSearchCV(\n\u001b[0;32m     27\u001b[0m     estimator\u001b[38;5;241m=\u001b[39mxgb_model,\n\u001b[0;32m     28\u001b[0m     param_grid\u001b[38;5;241m=\u001b[39mparam_grid,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     32\u001b[0m     verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m\n\u001b[0;32m     33\u001b[0m )\n\u001b[0;32m     35\u001b[0m \u001b[38;5;66;03m# Fit the grid search\u001b[39;00m\n\u001b[1;32m---> 36\u001b[0m \u001b[43mgrid_search\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     38\u001b[0m \u001b[38;5;66;03m# Print the best parameters and score\u001b[39;00m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest parameters:\u001b[39m\u001b[38;5;124m\"\u001b[39m, grid_search\u001b[38;5;241m.\u001b[39mbest_params_)\n",
      "File \u001b[1;32mc:\\Users\\arian\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1145\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1147\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1148\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1150\u001b[0m     )\n\u001b[0;32m   1151\u001b[0m ):\n\u001b[1;32m-> 1152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\arian\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:898\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    892\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[0;32m    893\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m    894\u001b[0m     )\n\u001b[0;32m    896\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[1;32m--> 898\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    900\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m    901\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m    902\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\arian\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1422\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1420\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1421\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1422\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\arian\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:845\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    837\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    838\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[0;32m    839\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    840\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    841\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[0;32m    842\u001b[0m         )\n\u001b[0;32m    843\u001b[0m     )\n\u001b[1;32m--> 845\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    846\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    847\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    848\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    849\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    850\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    851\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    852\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    853\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    854\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    855\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    856\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    857\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    858\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    859\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    860\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    862\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    863\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    864\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    865\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    866\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    867\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\arian\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\parallel.py:65\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     60\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     61\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     62\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     63\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     64\u001b[0m )\n\u001b[1;32m---> 65\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\arian\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\joblib\\parallel.py:1952\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1946\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[0;32m   1947\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[0;32m   1948\u001b[0m \u001b[38;5;66;03m# reach the first `yield` statement. This starts the aynchronous\u001b[39;00m\n\u001b[0;32m   1949\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[0;32m   1950\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 1952\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\arian\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\joblib\\parallel.py:1595\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[1;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[0;32m   1592\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[0;32m   1594\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[1;32m-> 1595\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[0;32m   1597\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[0;32m   1598\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[0;32m   1599\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[0;32m   1600\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[0;32m   1601\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\arian\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\joblib\\parallel.py:1699\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1692\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wait_retrieval():\n\u001b[0;32m   1693\u001b[0m \n\u001b[0;32m   1694\u001b[0m     \u001b[38;5;66;03m# If the callback thread of a worker has signaled that its task\u001b[39;00m\n\u001b[0;32m   1695\u001b[0m     \u001b[38;5;66;03m# triggered an exception, or if the retrieval loop has raised an\u001b[39;00m\n\u001b[0;32m   1696\u001b[0m     \u001b[38;5;66;03m# exception (e.g. `GeneratorExit`), exit the loop and surface the\u001b[39;00m\n\u001b[0;32m   1697\u001b[0m     \u001b[38;5;66;03m# worker traceback.\u001b[39;00m\n\u001b[0;32m   1698\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_aborting:\n\u001b[1;32m-> 1699\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_error_fast\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1700\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m   1702\u001b[0m     \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[0;32m   1703\u001b[0m     \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\arian\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\joblib\\parallel.py:1727\u001b[0m, in \u001b[0;36mParallel._raise_error_fast\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1725\u001b[0m \u001b[38;5;66;03m# Find the first job whose status is TASK_ERROR if it exists.\u001b[39;00m\n\u001b[0;32m   1726\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m-> 1727\u001b[0m     error_job \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjob\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mjob\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jobs\u001b[49m\n\u001b[0;32m   1728\u001b[0m \u001b[43m                      \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mjob\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstatus\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mTASK_ERROR\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m   1730\u001b[0m \u001b[38;5;66;03m# If this error job exists, immediatly raise the error by\u001b[39;00m\n\u001b[0;32m   1731\u001b[0m \u001b[38;5;66;03m# calling get_result. This job might not exists if abort has been\u001b[39;00m\n\u001b[0;32m   1732\u001b[0m \u001b[38;5;66;03m# called directly or if the generator is gc'ed.\u001b[39;00m\n\u001b[0;32m   1733\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m error_job \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\arian\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\joblib\\parallel.py:1727\u001b[0m, in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m   1725\u001b[0m \u001b[38;5;66;03m# Find the first job whose status is TASK_ERROR if it exists.\u001b[39;00m\n\u001b[0;32m   1726\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m-> 1727\u001b[0m     error_job \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m((job \u001b[38;5;28;01mfor\u001b[39;00m job \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs\n\u001b[0;32m   1728\u001b[0m                       \u001b[38;5;28;01mif\u001b[39;00m job\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m==\u001b[39m TASK_ERROR), \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m   1730\u001b[0m \u001b[38;5;66;03m# If this error job exists, immediatly raise the error by\u001b[39;00m\n\u001b[0;32m   1731\u001b[0m \u001b[38;5;66;03m# calling get_result. This job might not exists if abort has been\u001b[39;00m\n\u001b[0;32m   1732\u001b[0m \u001b[38;5;66;03m# called directly or if the generator is gc'ed.\u001b[39;00m\n\u001b[0;32m   1733\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m error_job \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'max_depth': [3, 5, 7, 10],\n",
    "    'learning_rate': [0.01, 0.1, 0.2, 0.3],\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'min_child_weight': [1, 3, 5],\n",
    "    'gamma':[0, 0.1, 0.2],\n",
    "    'subsample': [0.6, 0.8, 1.0],\n",
    "    'colsample_bytree': [0.6, 0.8, 1.0]\n",
    "}\n",
    "\n",
    "# Create an XGBClassifier\n",
    "xgb_model = XGBClassifier(\n",
    "    tree_method='hist',\n",
    "    predictor='gpu_predictor',\n",
    "    device='cuda',\n",
    "    objective='multi:softmax',\n",
    "    metric='mlogloss',\n",
    "    num_class=4\n",
    ")\n",
    "\n",
    "# Set up GridSearchCV with cross-validation\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=xgb_model,\n",
    "    param_grid=param_grid,\n",
    "    cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=42),\n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1,\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "# Fit the grid search\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Print the best parameters and score\n",
    "print(\"Best parameters:\", grid_search.best_params_)\n",
    "print(\"Best cross-validation score:\", grid_search.best_score_)\n",
    "\n",
    "# Use the best model for predictions\n",
    "best_model = grid_search.best_estimator_\n",
    "y_pred = best_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.0.6\n"
     ]
    }
   ],
   "source": [
    "import notebook\n",
    "print(notebook.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
